{"instruction": "Generate HLS code with the following instructions:", "input": "Generate the HLS code for a 2mm kernel function that performs a two-matrix multiply operation (D := alpha * A * B * C + beta * D) where A, B, C, and D are matrices of sizes 40x70, 70x50, 50x80, and 40x80 respectively. Ensure that the code accelerates the matrix multiply operation as a hardware function. Apply automatic optimization for pipeline, tile, and parallelization pragmas. Enable reduction for the 'tmp' and 'D' variables in the relevant loop levels to ensure the summation operates correctly during parallel processing. Use respective auto-tuning identifiers in the pragmas for the tool to automatically find appropriate factors.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 4\n__PARA__L4: 1\n__PARA__L5: 1\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: flatten\n__PIPE__L3: off\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Create an HLS-accelerated function `kernel_2mm` that performs a two-matrix multiply operation specified by the equation `D := alpha*A*B*C + beta*D`. Enable automatic optimization for pipeline, tiling, and parallelization on the loop levels, and ensure that the intermediate results and final updates utilize parallel reduction for accumulation.\n\n1. Annotate the function as a kernel for hardware acceleration.\n2. Automatically optimize the pipeline at each loop nesting level.\n3. Automatically tile the loops to potentially improve memory bandwidth utilization.\n4. Apply automatic parallelization to each loop to exploit data-level parallelism.\n5. Use parallel reduction with automatic factor for accumulating elements in `tmp` and `D` arrays to enhance the computation throughput within the innermost loops.\n\nCorrespondingly, set `#pragma ACCEL PIPELINE`, `#pragma ACCEL TILE FACTOR`, and `#pragma ACCEL PARALLEL FACTOR` to 'auto', and specify the parallel reduction variables explicitly.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 20\n__PARA__L4: 70\n__PARA__L5: 1\n__PIPE__L0: off\n__PIPE__L1: \n__PIPE__L2: \n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 4"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Consider a hardware acceleration kernel called 'kernel_2mm' that operates on matrices with specific sizes, using matrix multiplication followed by a scaling operation. Optimize the loop calculations automatically, while allowing for parallel execution where beneficial and efficient pipelining to enhance throughput. For the multiplication, create accumulators to prevent read-write conflicts. Let the tool decide the optimal sizes for tiling and the number of loop iterations to execute in parallel for enhanced data locality and parallelism. Apply these optimization pragmas to the various nested loops within the outer loops that iterate over the primary matrix dimensions.\n\nFor the pragmas:\n\n1. Specify that the function 'kernel_2mm' should be treated as a hardware kernel.\n2. Enable automatic loop pipelining for the outer loops to increase data throughput without specifying a fixed pipeline initiation interval.\n3. Allow the tool to automatically determine the tiling factor for the loops to improve data caching and reuse.\n4. Enable automatic parallel factor determination for the loops to benefit from data-level parallelism where possible.\n5. For the reduction operation inside parallel loops, specify that the accumulations on temporary variables ('tmp' and 'D') should concurrently occur without data hazards.\n", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 4\n__PARA__L3: 20\n__PARA__L4: 16\n__PARA__L5: 1\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: off\n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Generate HLS code that accelerates the execution of a 2mm matrix multiplication kernel by treating the entire function as a hardware kernel, and automatically managing the pipelining, tiling, and parallelization of the loop bodies, with a provision for parallel reductions where applicable.\n\n- Label the function as a hardware acceleration kernel.\n- Apply automatic pipelining to the first and second level loops with their respective pragmas.\n- Use automatic tiling for the loop iterations in both first and second level loops with their respective pragmas.\n- Enable automatic parallelization of all loops, including nested loops, with respective pragmas.\n- Specifically, for the reduction operations inside the first-level loop, ensure that the reduction on `tmp` is automatically set, as well as for the reduction on `D` in the second-level loop. Select the appropriate factor for parallelization dynamically for these reductions.\n\nIn the code, mark pragmas for pipeline, tile, and parallel with 'auto' and use placeholders `{__PIPE__L0}`, `{__TILE__L0}` `{__PARA__L0}`, `{__PIPE__L1}`, etc., to indicate that these values are to be automatically determined. Use 'reduction' in parallel pragmas to ensure proper handling of the reduction variables (`tmp` and `D`).", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 4\n__PARA__L3: 5\n__PARA__L4: 32\n__PARA__L5: 4\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: \n__PIPE__L3: off\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Convert the provided 2mm kernel computation into an accelerated hardware design with appropriate pragmas to optimize loops and memory access. First, declare the function as an acceleration kernel. Then, automatically optimize the main loops and their nested loops using pipeline, tiling, and parallelization. Additionally, ensure that the parallelized loops perform a reduction operation on the tmp and D matrices as appropriate. Let the compiler decide the specific factor values for pipelining, tiling, and parallelism.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 4\n__PARA__L4: 1\n__PARA__L5: 2\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: flatten\n__PIPE__L3: off\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Optimize the given 2mm kernel, which computes a two-matrix multiplication followed by the addition of a third matrix, using hardware acceleration. Automatically handle the pipelining, tiling, and parallelization of all loops for maximum efficiency. Apply loop tiling to split loops into smaller pieces for better data locality and pipelining to overlap loop execution. Additionally, enable loop parallelization to distribute the computations across multiple processing elements and apply reduction to handle dependencies in accumulation operations. Utilize the 'auto' directive to allow the HLS tool to determine the most suitable parallelization factor, tiling size, and pipelining strategy for each loop.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 4\n__PARA__L3: 80\n__PARA__L4: 1\n__PARA__L5: 4\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: flatten\n__PIPE__L3: \n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Generate HLS code for a matrix multiplication and addition kernel with the following optimizations: \n\n1. Designate the entire function as an acceleration kernel.\n2. Dynamically optimize the pipelining, tiling, and parallel processing of the outer loops for both matrix multiplication and addition, assigning values automatically.\n3. Specifically optimize the pipelining, tiling, and parallel processing of the inner loops with automatic factor assignment, and include reduction to accumulate the results properly for both tmp and D arrays.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 4\n__PARA__L3: 80\n__PARA__L4: 1\n__PARA__L5: 10\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: flatten\n__PIPE__L3: \n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Designate the following function as a hardware acceleration kernel, automate the pipelining, tiling, and parallel processing across all loops within the function with optimization heuristics determined by the compiler. Specifically, apply automatic pipelining, tiling, and parallelism to the loops for both initializing the 'tmp' array with the product of 'alpha', 'A', and 'B', and then updating array 'D' with the sum of 'beta' scaled 'D' and the product of 'tmp' and 'C'. Also, use automatic loop-dependent optimization for reduction in assignments to the 'tmp' and 'D' arrays during their respective accumulation processes.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 4\n__PARA__L4: 1\n__PARA__L5: 1\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: flatten\n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Generate an HLS C code for a matrix operation function that acts as a hardware acceleration kernel. The function, named 'kernel_2mm', computes the equation `D := alpha*A*B*C + beta*D` for given matrix sizes and scalar values alpha and beta. Apply automatic pipelining, tiling, and parallel processing optimizations, with particular emphasis on reducing the accumulation variables 'tmp' and 'D'. The optimization factors for each of these directives should be determined automatically by the HLS tool. Specifically, assign the pragma directives to allow for automatic optimization factor specification for pipeline, tile, and parallel execution of the code's nested loops while including reduction pragmas to handle dependencies in the accumulation statements.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 32\n__PARA__L4: 2\n__PARA__L5: 1\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: off\n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Convert the function `kernel_2mm` into a hardware-accelerated kernel, letting the HLS tool automatically decide the optimal pipelining, tiling, and parallelization strategies for both sets of nested loops. Additionally, for the innermost loops, enable a parallel reduction on the `tmp` and `D` arrays to combine values from parallel computations efficiently.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 4\n__PARA__L3: 32\n__PARA__L4: 32\n__PARA__L5: 2\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: off\n__PIPE__L3: off\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Accelerate the 'kernel_2mm' function with dynamic pragmas for improving throughput and parallelization; optimize loops through pipelining, tiling, and parallel execution with compiler-determined factors, and apply a parallel reduction to accumulate matrix multiplication results.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 4\n__PARA__L4: 1\n__PARA__L5: 1\n__PIPE__L0: off\n__PIPE__L1: \n__PIPE__L2: flatten\n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Generate HLS C code that treats a function as a hardware acceleration kernel, aiming to optimize matrix-multiplication and addition operations. Apply automatic optimization strategies for loop pipelining, tiling, and parallelization while preserving the loop structure and dependencies. Employ automatic factor determination for these optimizations. Specifically, enable parallel reduction for matrix updates to facilitate concurrent element computations, allowing the compiler to decide the parallelization factors. The code computes the result of \\( D := \\alpha \\cdot A \\times B \\times C + \\beta \\cdot D \\).", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 4\n__PARA__L3: 16\n__PARA__L4: 16\n__PARA__L5: 1\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: \n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 2"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Generate HLS C code for a 2mm kernel function with the following directives:\n\n1. Declare the function as a hardware acceleration kernel.\n2. Enable automatic pipeline optimization on the outer loops `i` and `j` across all nested levels to determine the best pipeline strategy.\n3. Use automatic tiling factors for all loops to partition the computation into smaller chunks based on available resources and data reuse opportunities.\n4. Enable automatic parallelization for the inner loops `k` while also reducing the 'tmp' array in the first set of nested loops and the 'D' array in the second set of nested loops, allowing the compiler to decide the parallelization factor for best performance.\n5. Perform the operation `D := alpha*A*B*C + beta*D` by first initializing 'tmp' with the product of `alpha*A*B`, and then updating 'D' with `beta*D + tmp*C`.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 4\n__PARA__L3: 80\n__PARA__L4: 1\n__PARA__L5: 50\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: flatten\n__PIPE__L3: off\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Designate the function 'kernel_2mm' as a hardware acceleration kernel, apply automatic loop pipelining, tiling, and parallelization at appropriate levels for optimized hardware generation, with specific pragma values set dynamically by the tool for each loop, and enable parallel reductions on temporary array computations.\n\n- Treat the 'kernel_2mm' function as a hardware acceleration kernel.\n- Enable automatic pipelining, tiling, and parallelization for the outer and inner loops, with specific optimization factors determined by the HLS tool.\n- In loops that accumulate values into 'tmp' and 'D', apply parallel reductions with automatic parallelization factors to optimize the associative operations for concurrent execution.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 4\n__PARA__L3: 80\n__PARA__L4: 1\n__PARA__L5: 1\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: \n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Generate HLS C code for a 2mm kernel function that performs a matrix multiplication and addition operation, ensuring to:\n\n1. Designate the main function as a hardware kernel for FPGA-based acceleration.\n2. Apply automatic optimization directives for pipelining, tiling, and parallelization to each loop nest, allowing the HLS tool to determine the optimal configuration for the pipelining, tile factor, and parallelism of the loops. These optimizations should be individually applied to each loop nest at loop levels L0, L1, L2, L3, L4, and L5.\n3. Within the first loop nest, initialize a matrix `tmp` by leveraging an automatic parallel factor with a reduction on `tmp`, optimizing the reduction operation across the k-dimension loop.\n4. Within the second loop nest, similarly apply an automatic parallel factor with a reduction on matrix `D`, optimizing the reduction operation across the k-dimension loop.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 4\n__PARA__L3: 80\n__PARA__L4: 1\n__PARA__L5: 5\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: flatten\n__PIPE__L3: \n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Generate an HLS C code for a 2mm kernel function that accelerates the computation of the matrix expression `D := alpha*A*B*C + beta*D`, optimizing for parallelism and pipeline execution. Apply automatic optimization with the following instructions:\n- Define the function as an accelerable hardware kernel.\n- For each loop level L0, L1, L2, and L3, enable automatic pipeline optimization, automatic loop tiling, and automatic parallelization with pragmas that let the compiler determine the best factors.\n- Enable automatic parallelization with reduction for the innermost loops L4 and L5, merging the result into the `tmp` and `D` arrays respectively, allowing the compiler to decide the parallelization factors.\n\nUse '#pragma ACCEL kernel' to identify the hardware kernel function,\n'#pragma ACCEL PIPELINE auto{}' to allow the compiler to optimize the loop pipelining with its own strategy,\n'#pragma ACCEL TILE FACTOR=auto{}' to enable automatic loop tiling optimization,\n'#pragma ACCEL PARALLEL FACTOR=auto{}' to automatically parallelize the loops, and \n'#pragma ACCEL PARALLEL reduction' to indicate which array is being reduced in the parallel loop, with an automatic factor chosen by the compiler.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 32\n__PARA__L4: 7\n__PARA__L5: 4\n__PIPE__L0: off\n__PIPE__L1: \n__PIPE__L2: \n__PIPE__L3: \n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Designate the following function as a hardware kernel for acceleration with automated optimizations applied to pivotal loop nests. Apply automatic pipeline optimization to the primary loop nests to enhance dataflow. Automatically define the tiling factor to partition the loops efficiently for parallel processing. Use automatic parallelization to further optimize loop iterations with parallel execution, and include reduction clauses for accumulations within loops to ensure correctness in concurrent scenarios. Utilize compiler-suggested pragma factors for all automated optimizations.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 32\n__PARA__L4: 32\n__PARA__L5: 1\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: \n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Here is a single comprehensive instruction to generate the specific HLS codes for the function `kernel_2mm`:\n\n\"Implement the function `kernel_2mm` as a hardware-accelerated kernel, which computes the matrix operation `D = alpha * A * B * C + beta * D`. Apply automatic loop optimization strategies for pipelining, tiling, and parallelism, where appropriate, based on the implementation's capability to improve performance, and use reduction for accumulating values in the matrix multiplication. Allow the compiler's heuristic to decide the optimization factors for each nested loop structure with `auto` syntax placeholders.\"", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 4\n__PARA__L4: 32\n__PARA__L5: 16\n__PIPE__L0: off\n__PIPE__L1: \n__PIPE__L2: off\n__PIPE__L3: off\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 8"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Designate the function 'kernel_2mm' to be synthesized as a hardware kernel, apply automatic pipelining, tiling, and parallelization for optimal performance on the nested loops responsible for matrix multiplication and addition, with specific optimization parameters determined at compile-time. Use parallel reductions to handle dependency in loop iterations involving summations.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 4\n__PARA__L3: 80\n__PARA__L4: 2\n__PARA__L5: 1\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: off\n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Designate the function 'kernel_2mm' as a computation unit for hardware acceleration and apply optimal automatic parallelism, pipelining, and tiling to all loops to efficiently compute the 2mm (two matrix multiply) kernel, which is a part of the polyhedral benchmark suite, ensuring data reduction is correctly managed for the appropriate loop variables.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 4\n__PARA__L4: 1\n__PARA__L5: 50\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: flatten\n__PIPE__L3: \n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Designate the subsequent function as a hardware acceleration kernel, apply automatic optimization to pipeline the outermost loops, automatically determine the tiling factor for loop optimizations, and set parallel processing with automatic factor determination, ensuring that intermediate values accumulated across iterations in nested loops that contribute to a single array index are reduced correctly and efficiently.\n\nSpecifically, use the following #pragma directives:\n\n- Treat 'kernel_2mm' as a hardware acceleration kernel with `#pragma ACCEL kernel`.\n- Automatic pipeline optimization for the first level loops (`i` loops) dealing with 'tmp' and 'D' matrices using `#pragma ACCEL PIPELINE auto`.\n- Automatic tiling factor for the first level loops (`i` loops) dealing with 'tmp' and 'D' matrices using `#pragma ACCEL TILE FACTOR=auto`.\n- Automatic parallel factor for the first level loops (`i` loops) dealing with 'tmp' and 'D' matrices using `#pragma ACCEL PARALLEL FACTOR=auto`.\n- Second level loop (`j` loop) over 'tmp' and 'D' matrices should also be optimized with automatic pipeline, tiling, and parallel factors respectively using the same set of #pragma directives as for the first level loops.\n- For the third level reduction loops (`k` loops), ensure parallel operations are efficiently handled, with intermediate sums reduced correctly using `#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto` for the first reduction loop and `#pragma ACCEL PARALLEL reduction = D FACTOR=auto` for the second reduction loop, allowing for automatic factor determination.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 32\n__PARA__L4: 1\n__PARA__L5: 1\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: off\n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Define a function `kernel_2mm` to perform a two-matrix multiply operation, where matrices `A`, `B`, `C`, and `D` are multiplied and scaled by factors `alpha` and `beta` respectively, with the result stored back in matrix `D`. This function is designated as a hardware acceleration kernel. Use automated optimization directives to improve performance without manually specifying pipeline depth, tile size, or parallelism factor. For the first loop nest which calculates `tmp = alpha * A * B`, apply automatic pipelining, tiling, and parallelization to the outer loops, and use automatic parallel reduction for the innermost loop writing to `tmp`. For the second loop nest which computes `D = beta * D + tmp * C`, again apply automatic pipelining, tiling, and parallelization to the outer loops and automatic parallel reduction for the innermost loop updating `D`.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 4\n__PARA__L3: 16\n__PARA__L4: 8\n__PARA__L5: 1\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: \n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 2"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Designate the `kernel_2mm` function to be synthesized into a hardware accelerator, automatically optimize pipelining, tiling, and parallelization for the loops, and also apply reduction to accumulate values within the innermost loops:\n\n- Use `#pragma ACCEL kernel` to indicate the transformation of the `kernel_2mm` function into an accelerator.\n- For outer loops (i and j), apply automatic optimization for pipelining, tiling, and parallel execution by writing `#pragma ACCEL PIPELINE auto`, `#pragma ACCEL TILE FACTOR=auto`, and `#pragma ACCEL PARALLEL FACTOR=auto` respectively before each loop.\n- For the innermost loop (k), use `#pragma ACCEL PARALLEL reduction` along with `FACTOR=auto` to allow concurrent reduction operations, where the reduction variable is `tmp` or `D`, automatically determining the parallelization factor.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 4\n__PARA__L3: 80\n__PARA__L4: 1\n__PARA__L5: 32\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: flatten\n__PIPE__L3: off\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Designate the function 'kernel_2mm' as a hardware acceleration kernel that computes the 2mm matrix-matrix multiplication and matrix addition with scalars 'alpha' and 'beta'. Optimize loops using automatic pipeline, tiling, and parallelization decisions by the compiler, setting them to their corresponding 'auto' strategy values. Moreover, apply parallel reduction on 'tmp' and 'D' to efficiently accumulate results for the innermost loop computations.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 4\n__PARA__L4: 4\n__PARA__L5: 50\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: off\n__PIPE__L3: \n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Generate an HLS code for a 2mm kernel function that performs a matrix multiplication and addition operation with two stages, optimizing for hardware acceleration with automatic pragma values. Initially, declare the kernel function with appropriate data types and dimensions for input and output matrices, and apply the appropriate kernel pragma. Then, for the first stage, create three nested loops, setting the outermost loop to automatically optimize pipeline, tiling, and parallelism without specifying values. Inside the second loop, initialize the temporary matrix with zeros and apply automated parallel reductions for the innermost loop, ensuring it is optimizing the matrix multiplication between alpha, matrix A, and matrix B. Subsequently, establish the second stage through another three nested loops, optimizing the outermost loop just as before, and in the second loop, apply the beta scaling to the matrix D. Again, implement automated parallel reductions for the innermost loop which is tasked with adding the product of the temporary matrix and matrix C to the scaled matrix D. Make sure to encapsulate both computational stages within the scope pragmas.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 2\n__PARA__L4: 70\n__PARA__L5: 50\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: off\n__PIPE__L3: \n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Generate an HLS C function called `kernel_2mm` that is designated as a hardware kernel for acceleration, performing matrix multiplications and additions on 2D arrays. In the first part of the function, compute a temporary matrix `tmp` by multiplying `alpha` with each element of the matrix product of `A` and `B`, applying automatic pipelining, tiling, and parallel processing decisions for the outer loops. Inside the innermost loop of the first part, use automatic parallel processing with a reduction on the `tmp` matrix. In the second part of the function, update matrix `D` by multiplying each element by `beta` and adding the product of the `tmp` matrix and matrix `C`, again applying automatic pipelining, tiling, and parallel processing for the outer loops, and use automatic parallel processing with a reduction on the `D` matrix for the innermost loop.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 4\n__PARA__L4: 1\n__PARA__L5: 50\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: flatten\n__PIPE__L3: off\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 4"}
{"instruction": "Generate HLS code with the following instructions:", "input": "To generate the HLS codes provided, instruct the following:\n\nDesignate the function 'kernel_2mm' as a hardware acceleration kernel. Then, apply pipeline, tiling, and parallel optimization directives with automatic determination of factor values to the loops for maximum efficient use of hardware resources. Specifically, enable automatic pipelining, automatic tiling, and automatic parallelism for the outer loops that iterate over 'i' and 'j' in both the matrix multiplication sections. Also, apply parallel reduction with automatic factor determination to the innermost 'k' loops, to optimize the accumulation of 'tmp' and 'D' matrices respectively.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 4\n__PARA__L4: 1\n__PARA__L5: 8\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: flatten\n__PIPE__L3: off\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Instruct the HLS tool to optimize the function `kernel_2mm` for hardware acceleration by automatically selecting pipeline, tile, and parallelism settings for each nested loop, and enabling parallel reduction for specific accumulation operations. For the outermost loops, enable automatic optimization for maximum performance without specifying concrete values, but for the inner loops handling the multiplication and accumulation, explicitly set automatic directives to allow for parallel reduction on the `tmp` and `D` matrices.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 4\n__PARA__L4: 1\n__PARA__L5: 50\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: flatten\n__PIPE__L3: off\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Designate the function 'kernel_2mm' to be synthesized as a hardware accelerator. Automatically optimize the pipeline, loop tiling, and parallel processing of the nested loops with pragmas to improve performance. These optimizations should allow the tool to decide the best factors for pipelining, data tiling, and parallelization. Additionally, for the two innermost loops that update 'tmp' and 'D' matrices, enable parallel reduction with automatic determination of the optimal parallel factor.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 8\n__PARA__L1: 1\n__PARA__L2: 2\n__PARA__L3: 1\n__PARA__L4: 32\n__PARA__L5: 1\n__PIPE__L0: \n__PIPE__L1: off\n__PIPE__L2: \n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Instruct the HLS tool to optimize the function named `kernel_2mm` by analyzing it as a target for hardware acceleration: Enable automatic pipeline optimization for the outer loops to allow for concurrent execution of sequential iterations, and enable automatic tile and parallel factor optimizations for both loops and inner reductions. Additionally, use parallel reduction to improve the computation of the matrix multiplications within the innermost loops, where the accumulation variable `tmp` is updated with the product of matrices `A` and `B`, and `D` is updated with the result of the operation `tmp * C`. The auto-pragmas inserted should allow the HLS tool to determine the optimal values for pipelining, tiling, and parallelization.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 4\n__PARA__L4: 1\n__PARA__L5: 25\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: flatten\n__PIPE__L3: off\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "To generate the provided HLS code in C, the following is a comprehensive yet concise natural language instruction that describes the process and the specific `#pragma` directives and values to be used:\n\n\"Declare a function 'kernel_2mm' intended for hardware acceleration that computes the matrix expression D = alpha\\*A\\*B + beta\\*D, where A, B, C, and D are input matrices, and alpha and beta are scalar values. For each nested loop, use automated directives to improve parallelism, pipelining, and tiling for optimizations without specifying exact factors. Additionally, set parallelism with automatic factor determination and appropriate reductions for temporary result accumulation in subexpressions within innermost loops.\"\n\nThis instruction corresponds to the following HLS codes and pragmas:\n\n- `#pragma ACCEL kernel` is described as \"Declare the following function as a hardware kernel for acceleration.\"\n- `#pragma ACCEL PIPELINE auto{__PIPE__Lx}` corresponds to \"Enable pipelining with automatic factor determination for each level of nested loops, where 'x' represents the loop level.\"\n- `#pragma ACCEL TILE FACTOR=auto{__TILE__Lx}` matches \"Enable tiling with automatic factor determination to divide the loop iterations into manageable blocks at each level of nested loops.\"\n- `#pragma ACCEL PARALLEL FACTOR=auto{__PARA__Lx}` corresponds to \"Automatically determine and apply the parallelism factor to execute iterations concurrently at each level of nested loops without specifying exact factors.\"\n- `#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__Lx}` and `#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__Lx}` describe \"Automatically determine and apply the parallelism factor to execute cumulative operations on 'tmp' or 'D' concurrently in the innermost loops, enabling reduction to accumulate the results of these operations.\"\n", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 4\n__PARA__L4: 1\n__PARA__L5: 4\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: flatten\n__PIPE__L3: off\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Define a function as a hardware acceleration kernel to allow for potential parallel execution and optimization. Within this kernel, perform a two-part matrix operation where initially a temporary matrix is computed as the result of multiplying a matrix `A` with dimensions 40x70 by matrix `B` with dimensions 70x50 and a scalar `alpha`. Optimize the first nested loop iteration for parallel processing and pipelining, with specific compile-time optimization settings for loop tiling, pipelining, and parallel factor determined by the compiler. Then, update matrix `D` with dimensions 40x80 by multiplying it by a scalar `beta` and adding the product of the temporary matrix and matrix `C` with dimensions 50x80. Similarly, optimize the second nested loop iteration for parallel processing and pipelining, with loop optimization factors also determined by the compiler. Utilize reduction clauses to ensure the correct computation of the output during the parallelization of innermost operations on the matrices.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 8\n__PARA__L3: 1\n__PARA__L4: 32\n__PARA__L5: 1\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: off\n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Consider a matrix multiplication and addition kernel that should be optimized for hardware acceleration using HLS pragmas. Implement the following directives:\n\n1. Mark the kernel function as a candidate for hardware acceleration.\n2. Enable automatic pipeline optimization for the outer loops where the loop indices are `i` and `j`, allowing the compiler to decide the best way to pipeline these loops.\n3. Allow the compiler to automatically determine tiling factors for the nested loops, effectively splitting them into smaller chunks for potential parallel execution.\n4. Permit the compiler to automatically parallelize the loops while also specifying automatic parallelization factors, which determine how many loop iterations can be executed in parallel.\n5. In the innermost loops, where the indices are `k`, enable the reduction pattern for the accumulation into the `tmp` array and the `D` array, and allow automatic determination of the parallelization factors for these loops.\n\nUse the following HLS pragma values:\n- `#pragma ACCEL kernel`: to treat the function as a hardware kernel.\n- `#pragma ACCEL PIPELINE auto`: to enable automatic loop pipelining.\n- `#pragma ACCEL TILE FACTOR=auto`: to enable automatic loop tiling.\n- `#pragma ACCEL PARALLEL FACTOR=auto`: to enable automatic loop parallelization.\n- `#pragma ACCEL PARALLEL reduction=` for the reduction pattern: specify the variable (`tmp` or `D`) followed by `FACTOR=auto` for automatic factor determination.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 4\n__PARA__L3: 5\n__PARA__L4: 1\n__PARA__L5: 50\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: flatten\n__PIPE__L3: \n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Convert the 2D matrix multiplication and addition algorithm into a hardware-accelerated function, allowing for automatic optimization of loop pipelining, tiling, and parallelization, while also optimizing for parallel reductions within nested loops where designated. Specifically, adjust the pipelining, tiling, and parallelization factors for each loop at compile time based on the provided annotations and ensure that loop-carried dependencies in the reduction operations for computing the `tmp` and `D` matrices are explicitly handled to take advantage of parallel acceleration.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 4\n__PARA__L4: 1\n__PARA__L5: 5\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: flatten\n__PIPE__L3: off\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "To generate the provided HLS C code, the following instruction in natural language can be used:\n\n\"Define a hardware-accelerated kernel function called 'kernel_2mm' that takes as its arguments two integer dimensions 'ni', 'nj', 'nk', 'nl' and two floating-point scalar values 'alpha', 'beta', along with four 2D double-precision floating-point arrays 'tmp', 'A', 'B', 'C', and 'D'. The function computes the equation 'D := alpha*A*B + beta*D' via a two-step matrix multiplication and addition process. For the matrix multiplications and additions, all outer loops should be automatically optimized with pipelining, tiling, and parallel processing strategies, the levels of which are to be automatically determined at compile time. Additionally, for innermost loops where the 'tmp' and 'D' arrays have their values accumulated, apply parallel reduction with automatic factor discovery. Use appropriate pragmas to ensure these optimizations are applied at every loop nest level.\" \n\nThis description corresponds to the provided HLS C code with `#pragma ACCEL` directives:\n\n1. `#pragma ACCEL kernel` for treating the function as a hardware kernel.\n2. `#pragma ACCEL PIPELINE auto` for enabling automatic loop pipelining optimization.\n3. `#pragma ACCEL TILE FACTOR=auto` for automatic tiling factor computation.\n4. `#pragma ACCEL PARALLEL FACTOR=auto` for automatic parallel factor computation.\n5. `#pragma ACCEL PARALLEL reduction = <array>` with `FACTOR=auto` for enabling automatic parallel reduction on specified arrays within the innermost loops.\n\nReplace `auto` with specific pragma values to instruct the compiler on the optimization levels for each loop if auto-optimization is not preferred.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 16\n__PARA__L4: 70\n__PARA__L5: 10\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: off\n__PIPE__L3: off\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 2"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Treat the function `kernel_2mm` as a hardware acceleration kernel. Apply automatic optimization strategies for pipelining, tiling, and parallelizing all loops. Utilize loop-independent intermediate reductions within parallelized `k` loops to accumulate results for arrays `tmp` and `D`. Automatically determine the optimal values for pipeline stages, tile sizes, and parallelization factors for each loop level.\n\nSpecifically, for the outer two `i` loops, as well as the nested `j` loops within each, enable automatic pipelining, tiling, and parallelization; the HLS tool should decide the pragmas' values by replacing `auto{__PIPE__Lx}`, `auto{__TILE__Lx}`, and `auto{__PARA__Lx}` with the appropriate values for each loop (`x` being the loop level identifier). Use parallel reductions for `tmp` and `D` arrays within the innermost `k` loops with automatic factor determination, to efficiently compute the matrix multiplications and additions that contribute to each element of corresponding arrays.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 4\n__PARA__L3: 16\n__PARA__L4: 8\n__PARA__L5: 1\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: off\n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 2"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Define a hardware acceleration function `kernel_2mm` that performs matrix operations on arrays `A`, `B`, `C`, `D`, and an intermediate `tmp`, where `D` is updated based on the equation `D := alpha*A*B + beta*D`. For each distinct loop level within the function, enable automatic optimization of pipelining, tiling, and parallelization, and allow for reduction optimization where the updates to `tmp` and `D` arrays are concerned.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 4\n__PARA__L3: 80\n__PARA__L4: 1\n__PARA__L5: 8\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: flatten\n__PIPE__L3: \n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "To generate the provided HLS codes with pragma directives in C, use the following comprehensive but concise natural language instruction:\n\n\"Create a hardware-accelerated kernel function named 'kernel_2mm' that performs a two-matrix multiplication with scaling factors. The function takes matrix dimensions ni, nj, nk, and nl, scaling factors alpha and beta, and matrices A, B, C, D, and tmp as inputs. Use automatic pragma directives to optimize pipelining, tiling, and parallelization of the nested loops. Apply automatic parallel reduction on the appropriate variables within the innermost loops to efficiently accumulate the matrix multiplication results. Automatically determine the pragma factors for pipelining, tiling, and parallelization, but do not specify the exact values, allowing the HLS tool to decide them.\"\n\nSpecific #pragma values and their descriptions in natural language:\n- Treat the following function as a hardware kernel for acceleration: `#pragma ACCEL kernel`\n- Autotune loop pipelining optimization: `#pragma ACCEL PIPELINE auto{__PIPE__Lx}`\n- Autotune tiling optimization for loop unrolling and partitioning: `#pragma ACCEL TILE FACTOR=auto{__TILE__Lx}`\n- Autotune parallel processing for loops: `#pragma ACCEL PARALLEL FACTOR=auto{__PARA__Lx}`\n- Enable automatic parallel reduction for summation within the loop: `#pragma ACCEL PARALLEL reduction = <variable> FACTOR=auto{__PARA__Lx}`\n\nPlease replace `<variable>` with 'tmp' or 'D' depending on which loop the pragma applies to. The placeholders `__PIPE__Lx`, `__TILE__Lx`, and `__PARA__Lx` should be substituted with the appropriate loop labels assigned by the HLS tool during optimization. Each loop will have a unique label (Lx-like identifier) for precise control and tuning.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 2\n__PARA__L3: 5\n__PARA__L4: 70\n__PARA__L5: 1\n__PIPE__L0: off\n__PIPE__L1: \n__PIPE__L2: \n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Designate a function as a hardware acceleration kernel capable of multiplying and adding matrices. Allow automatic optimization of the loop pipelining, tiling, and parallel factor adjustments. Employ parallel reduction for accumulations within the matrix multiplications. \n\nSpecific #pragma instructions:\n- Treat 'void kernel_2mm' function as a hardware kernel for acceleration: `#pragma ACCEL kernel`\n- For the loops labeled with __PIPE__L0, __PIPE__L1, __PIPE__L2, __PIPE__L3, let the compiler decide whether to pipeline: `#pragma ACCEL PIPELINE auto`\n- For the loops labeled with __TILE__L0, __TILE__L1, __TILE__L2, __TILE__L3, let the compiler determine the optimal tiling factor: `#pragma ACCEL TILE FACTOR=auto`\n- For parallel execution, let the compiler optimize the parallel factor automatically for loops labeled with __PARA__L0, __PARA__L1, __PARA__L2, __PARA__L3: `#pragma ACCEL PARALLEL FACTOR=auto`\n- For the k-innermost loops (reductions on 'tmp' and 'D'), enable parallel reductions to allow concurrent accumulation with automatic factor adjustments labeled with __PARA__L4 and __PARA__L5: `#pragma ACCEL PARALLEL reduction = [array] FACTOR=auto` \n\nThe `auto` directive indicates that the compiler can automatically choose the appropriate parameters for pipelining, tiling, and parallelism to optimize hardware utilization.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 4\n__PARA__L3: 16\n__PARA__L4: 10\n__PARA__L5: 2\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: off\n__PIPE__L3: \n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Designate the function `kernel_2mm` as a hardware acceleration kernel that computes the matrix operation `D = alpha * A * B * C + beta * D` with size parameters `ni`, `nj`, `nk`, `nl`, and the corresponding matrices `tmp`, `A`, `B`, `C`, and `D`. Apply automatic pipelining, tiling, and parallelization directives to optimize all the nested loops, allowing the compiler to determine the best optimization factors. Include parallel reduction for accumulations within the multiply-accumulate operations to further enhance parallelism.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 4\n__PARA__L4: 32\n__PARA__L5: 16\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: off\n__PIPE__L3: off\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 8"}
{"instruction": "Generate HLS code with the following instructions:", "input": "To generate the given HLS codes in C, provide the following comprehensive yet concise instruction:\n\n\"Create a hardware-accelerated kernel function for a two-matrix multiply-add operation that first computes an intermediate result `tmp` by multiplying matrix `A` with `B` scaled by `alpha`, then updates matrix `D` with the intermediate result `tmp` multiplied by matrix `C`, scaled by `beta` and added to the previously scaled matrix `D`. Optimize all loops automatically for parallelization, pipelining, and tiling, with specific optimization parameters to be automatically determined by the HLS tool. Additionally, for the innermost loops that accumulate results to `tmp` and `D`, employ automatic parallel reduction to optimize the summation operations.\" \n\nCorresponding pragma instructions:\n\n1. Use `#pragma ACCEL kernel` to treat the function as a hardware-accelerated kernel.\n2. For the outer loops processing `tmp` and `D`, apply `#pragma ACCEL PIPELINE auto`, `#pragma ACCEL TILE FACTOR=auto`, and `#pragma ACCEL PARALLEL FACTOR=auto` to allow automatic loop optimization for pipelining, tiling, and parallel processing, respectively.\n3. For the inner loops calculating the products and accumulating into `tmp` and `D`, use `#pragma ACCEL PARALLEL reduction = [variable] FACTOR=auto` to enable automatic parallel reduction for efficient accumulation.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 32\n__PARA__L1: 1\n__PARA__L2: 2\n__PARA__L3: 1\n__PARA__L4: 32\n__PARA__L5: 1\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: \n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Designate the function `kernel_2mm` as a hardware acceleration kernel, and for all layers of loops within this function, allow the compiler to automatically select the best optimization strategies for loop pipelining, tiling, and parallel execution. Additionally, for the innermost loops that accumulate results into `tmp` and `D`, enable parallel reduction with automatic factor selection to potentially enhance performance.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 4\n__PARA__L4: 4\n__PARA__L5: 50\n__PIPE__L0: off\n__PIPE__L1: \n__PIPE__L2: \n__PIPE__L3: \n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Define a hardware acceleration kernel function named `kernel_2mm` that computes a doubly nested matrix multiplication (4 matrix inputs) and scales two of the input matrices with factors `alpha` and `beta`. The function is parameterized for matrix dimensions `ni`, `nj`, `nk`, and `nl`, with double-precision floating-point matrices `A`, `B`, `C`, `D`, and a temporary matrix `tmp`. Use automatic optimization heuristics for pipelining, tiling, and parallelization for each nested loop, and enable parallel reduction for intermediate accumulation in `tmp` and the final accumulation in `D`. Apply these optimizations hierarchically to outer and inner loops with pragma values set to auto, allowing the HLS tool to determine the appropriate factors.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 16\n__PARA__L1: 1\n__PARA__L2: 2\n__PARA__L3: 1\n__PARA__L4: 32\n__PARA__L5: 1\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: \n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Designate the function 'kernel_2mm' as a hardware acceleration kernel, then optimize its nested loops for performance using HLS pragmas. Automatically determine the optimal loop pipelining, tiling, and parallelization strategies for all the loops. Explicitly perform a reduction for parallel loops, ensuring that writes to the 'tmp' and 'D' arrays are correctly synchronized.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 4\n__PARA__L3: 80\n__PARA__L4: 1\n__PARA__L5: 16\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: flatten\n__PIPE__L3: \n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Generate a hardware-accelerated 2mm kernel function that computes the matrix multiplication and addition expression `D = alpha * A * B * C + beta * D` with optimization directives tailored for pipelining, tiling, and parallel execution. Use `auto` values for the pragmas to let the compiler determine the most efficient configuration. Enable reductions for proper accumulation of values in the `tmp` and `D` matrices, which have various dimensions as provided in the function arguments.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 4\n__PARA__L3: 80\n__PARA__L4: 1\n__PARA__L5: 1\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: off\n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Define the following function 'kernel_2mm' as a hardware acceleration kernel, set automatic optimization for pipeline, tile, and parallelization strategies for each loop, and include reduction clauses for partial results in the corresponding nested loops.\n\nFor the outermost loops labelled 'L0' and 'L1', apply automatic pipeline optimization, automatic tiling, and automatic parallelization. Inside the first loop nest labelled 'L2', automatically optimize these same strategies for iterating over the 'tmp' array, where 'tmp' is also subject to parallel reduction during the innermost 'k' loop labelled 'L4'.\n\nSimilarly, for the next loop nest labelled 'L3', apply the same automatic optimizations when iterating over matrix 'D', with 'D' being the target of parallel reduction within the innermost 'k' loop labelled 'L5'. Use the pragma values:\n- `#pragma ACCEL PIPELINE auto`\n- `#pragma ACCEL TILE FACTOR=auto`\n- `#pragma ACCEL PARALLEL FACTOR=auto`\n- `#pragma ACCEL PARALLEL reduction = <array> FACTOR=auto`\n\nAdjust these optimizations to allow each loop to run efficiently on hardware while respecting dependencies.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 4\n__PARA__L3: 16\n__PARA__L4: 7\n__PARA__L5: 1\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: \n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 2"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Create a multi-level loop-nested hardware kernel function named 'kernel_2mm' for matrix multiplication and addition with double-precision floating-point numbers. Enable automatic optimization for pipelining, data tiling, and parallel execution with machine learning-based factor suggestions for all loops. Additionally, apply parallel reduction for specific intermediate results within the inner loops. Use pragma annotations to manage these optimizations and reductions.\n\nTo describe the process and #pragma values in the provided code:\n\n1. Mark the function 'kernel_2mm' which takes multiple parameters including matrix sizes (ni, nj, nk, nl) and matrices (A, B, C, D) as well as scalars (alpha, beta) as a hardware acceleration candidate.\n2. Automatically determine and apply optimization strategies for each level of the loop nests to efficiently utilize hardware resources.\n    - For the outer loops 'i' in both matrix operations, use automatic pipeline optimization to potentially improve throughput.\n    - For the first-level inner loops 'j', enable automatic data tiling optimization to break down the computation into smaller chunks that may fit better into local memory and pipeline optimization to execute loop iterations quickly.\n    - Apply automatic parallelization for the innermost loops 'k' to execute operations concurrently wherever safe, and use parallel reduction for loop-carried dependencies on 'tmp' and 'D' arrays.\n3. Assign machine-learning optimized #pragma factors for determining the specific values for PIPELINE, TILE, and PARALLEL pragmas where 'auto{__PIPE__L*}', 'auto{__TILE__L*}', and 'auto{__PARA__L*}' represent the auto-suggested values for loop levels 0 to 5 respectively. This is indicated by keywords followed by 'auto' in the pragma statements.\n4. Use 'reduction' to specify which variables are being reduced in the inner loops and ensure that their updates are done in a parallel-reducible manner.\n\nEnsure that all loops are properly annotated to reflect these optimization strategies using appropriate #pragma directives.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 20\n__PARA__L4: 1\n__PARA__L5: 1\n__PIPE__L0: off\n__PIPE__L1: \n__PIPE__L2: flatten\n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "To generate the provided HLS C code with the appropriate #pragma values for the 2mm kernel, you should give the following instruction:\n\n\"Create a function designated as a hardware acceleration kernel that computes the 2mm operation\u2014a double matrix multiplication combined with a scaling of the resultant and an addition with a scaling of another matrix. Ensure that the first-level loops, which iterate over the elements of temporary and result matrices, are automatically optimized for parallel execution, pipelining, and tiling with the compiler deciding the specific factors. For the nested loops performing the actual dot product and addition calculations, enable parallelism with an automatic factor, and enable reduction to safely accumulate values into the shared result array elements. Do not specify fixed factors, but indicate that they should automatically be determined for efficient resource utilization and pipeline stages. This will reflect in pragma directives with 'auto' for the pipeline, tile, and parallel factors, and 'reduction' associated with the relevant array names for each innermost loop.\"", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 4\n__PARA__L4: 1\n__PARA__L5: 50\n__PIPE__L0: off\n__PIPE__L1: \n__PIPE__L2: flatten\n__PIPE__L3: off\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Create a high-level synthesis C function named 'kernel_2mm' which serves as an accelerated hardware kernel. The function processes a matrix multiplication followed by an addition according to the formula D := alpha * A * B * C + beta * D, using four 2D arrays A, B, C, and D of fixed sizes, and a temporary array 'tmp'. Use automatic optimization heuristics for pipelining, tiling, and parallelizing the loops, along with automatic parallel reduction for appropriate accumulations within the loops. Apply these optimizations at every loop level where specified, and indicate the loop level by using the placeholders __PIPE__Lx, __TILE__Lx, and __PARA__Lx, with 'x' representing the respective loop level depth starting from 0 for the outermost loop.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 2\n__PARA__L4: 70\n__PARA__L5: 1\n__PIPE__L0: off\n__PIPE__L1: \n__PIPE__L2: off\n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Generate HLS C code for a 2mm kernel function that accelerates the computation of the expression `D = alpha*A*B*C + beta*D`. Set the first outer loop iterating over a 40x50 `tmp` array, with automatic determination of pipelining, tiling, and parallelization for optimal performance. Also, inside this loop, parallelize the reduction of the `tmp` array with automatic optimization. For the second outer loop, which iterates over a 40x80 `D` array, apply similar automatic optimizations to the loop's iterations, as well as parallelize the reduction of the `D` array. Add pragmas to treat the function as a hardware kernel and to enable loop optimizations with symbolic names linked to pragmas for easier future adjustments.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 4\n__PARA__L3: 4\n__PARA__L4: 1\n__PARA__L5: 1\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: flatten\n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Optimize the function 'kernel_2mm' as a hardware acceleration kernel, where the function performs a matrix multiplication followed by a matrix addition as per the equation D := alpha * A * B * C + beta * D. Auto-tune the pipelining, tiling, and parallelization for the loops to achieve the best performance based on the available hardware resources. For matrix computations, specifically enable reduction optimization on the accumulator variables 'tmp' and 'D' during the corresponding parallel loop execution. \n\n- Treat 'kernel_2mm' as a hardware kernel for acceleration.\n- Automatically determine the pipelining strategy for the first-level loops iterating over 'i' for both matrix computations.\n- Automatically determine the tile sizes for the first-level loops iterating over 'i' for both matrix computations.\n- Automatically determine the parallel factors for the first-level loops iterating over 'i' for both matrix computations.\n- Inside the first matrix computation, automatically determine the pipelining, tiling, and parallelization strategies for the second-level loop iterating over 'j'.\n- Enable parallel reduction on 'tmp' with auto-tuned parallel factors during the k-loop inside the j-loop of the first matrix computation.\n- Inside the second matrix computation, automatically determine the pipelining, tiling, and parallelization strategies for the second-level loop iterating over 'j'.\n- Enable parallel reduction on 'D' with auto-tuned parallel factors during the k-loop inside the j-loop of the second matrix computation.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 2\n__PARA__L4: 70\n__PARA__L5: 32\n__PIPE__L0: off\n__PIPE__L1: \n__PIPE__L2: off\n__PIPE__L3: off\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 8"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Designate the function `kernel_2mm` as a dedicated hardware acceleration kernel, and configure automated optimization directives for all loops within to improve parallelism, pipelining, and data tiling for performance gains while maintaining the original loop structures and their full iteration counts. Include directives to perform automatic reductions on the temporary storage arrays `tmp` and `D` to efficiently aggregate results across iterations within their respective loops.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 5\n__PARA__L4: 1\n__PARA__L5: 32\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: flatten\n__PIPE__L3: off\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 2"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Instruct the HLS tool to consider the 'kernel_2mm' function as a hardware acceleration kernel. Inside this function:\n\n1. Enable auto-pipelining for the first level 'i' loops iterating over 'tmp' and 'D' arrays.\n2. Allow the tool to automatically select the tiling factors for the first level 'i' loops.\n3. Permit the tool to automatically determine the parallelization factors for the first level 'i' loops.\n4. In the nested 'j' loop where 'tmp' is being calculated, auto-pipeline the loop and automatically select both the tiling and parallelization factors.\n5. Apply parallel reduction on 'tmp' with an automatic factor in the innermost 'k' loop for computing 'tmp'.\n6. Similarly, in the outer loop for calculating 'D', auto-pipeline and automatically choose the tiling and parallelization factors.\n7. Implement parallel reduction on 'D' with an automatic factor in the inner 'k' loop for updating 'D'.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 4\n__PARA__L4: 70\n__PARA__L5: 50\n__PIPE__L0: off\n__PIPE__L1: \n__PIPE__L2: off\n__PIPE__L3: off\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Designate the function 'kernel_2mm' as a hardware acceleration kernel. Allow the compiler to automatically determine the optimal settings for pipelining, tiling, and parallel execution for all loops. For the innermost loops that compute the matrix product and the matrix addition, enable parallel reduction on the result matrices 'tmp' and 'D' respectively. Use auto-tuning to find the appropriate factor for parallelism without specifying a fixed number.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 8\n__PARA__L1: 40\n__PARA__L2: 2\n__PARA__L3: 4\n__PARA__L4: 32\n__PARA__L5: 1\n__PIPE__L0: \n__PIPE__L1: \n__PIPE__L2: \n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Declare a function 'kernel_2mm' as a hardware kernel to perform a 2mm computation (alpha * A * B * C + beta * D) on matrices of fixed dimension, selectively applying pipeline, tiling, and parallel optimization pragmas at each loop nest while allowing the HLS tool to automatically determine the best parameters for these optimizations.\n\nHere's the instruction in a more direct format:\n\nDefine the 'kernel_2mm' function with parameters for matrix dimensions, scaling factors alpha and beta, and input/output matrices. Apply the kernel pragma to indicate hardware acceleration. At the outermost level of each loop nest, use pipeline, tiling, and parallel pragmas but let the HLS tool decide the factors automatically. Inside the loops performing matrix multiplication and addition, apply a parallel pragma with automatic factor selection and specify a reduction operation on the respective output matrix elements.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 4\n__PARA__L4: 70\n__PARA__L5: 2\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: off\n__PIPE__L3: off\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Designate the function 'kernel_2mm' as a dedicated hardware acceleration kernel. Apply automatic pipelining, tiling, and parallelization strategies for optimal loop execution without explicitly specifying the factors; instead, allow the HLS tool to determine the best values. Also, employ parallel reduction in specific loops to efficiently accumulate results into the 'tmp' and 'D' matrices.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 8\n__PARA__L1: 1\n__PARA__L2: 2\n__PARA__L3: 8\n__PARA__L4: 32\n__PARA__L5: 1\n__PIPE__L0: \n__PIPE__L1: off\n__PIPE__L2: \n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Optimize the given matrix multiplication and accumulation function 'kernel_2mm' targeting hardware acceleration by allowing the compiler to decide the best way to pipeline both main loops and their nested loops, as well as tiling and parallelizing them for efficient execution, while also specifying that reductions on 'tmp' and 'D' matrices should be parallelized. Use appropriate #pragma directives before each loop to convey these optimizations, and also mark the function as a hardware kernel.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 5\n__PARA__L4: 32\n__PARA__L5: 1\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: off\n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 8"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Define a function as a hardware acceleration kernel that performs a two-matrix multiplication operation with scaling factors, and then adds the result to a scaled version of another matrix. Enable automatic optimization for loop pipelining, tiling, and parallel processing to improve performance. Specifically, for each loop, determine the optimal level of pipelining, tiling, and parallel execution automatically. Additionally, enable parallel reduction for the accumulation operations within the innermost loops to optimize data aggregation. Use pragma directives as follows: \n\n- Treat the entire function as a hardware acceleration kernel.\n- For the outer two loop nests, automatically optimize the loops for pipelining, tiling, and parallelism.\n- For the inner loops, enable parallel reduction to accumulate the products efficiently and automatically optimize these loops for parallelism.\n\nHere is a description of each pragma directive used in accordance with the task structure:\n\n- `#pragma ACCEL kernel`: Treat the following function as a hardware kernel for acceleration.\n- For each outer loop (`i` loop for matrices `tmp` and `D`):\n  - `#pragma ACCEL PIPELINE auto{__PIPE__L0}` / `#pragma ACCEL PIPELINE auto{__PIPE__L1}`: Automatically optimize the loop for pipelining to improve throughput.\n  - `#pragma ACCEL TILE FACTOR=auto{__TILE__L0}` / `#pragma ACCEL TILE FACTOR=auto{__TILE__L1}`: Automatically determine the tiling factor for breaking the loop into smaller chunks.\n  - `#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}` / `#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}`: Automatically determine the parallelism factor for executing iterations in parallel.\n- For each intermediate loop (`j` loop for matrices `tmp` and `D`):\n  - `#pragma ACCEL PIPELINE auto{__PIPE__L2}` / `#pragma ACCEL PIPELINE auto{__PIPE__L3}`: Similarly, optimize these loops automatically for pipelining.\n  - `#pragma ACCEL TILE FACTOR=auto{__TILE__L2}` / `#pragma ACCEL TILE FACTOR=auto{__TILE__L3}`: Automatically determine the optimal tiling factor for these loops.\n  - `#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}` / `#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}`: Automatically optimize these loops for executing iterations in parallel.\n- For each innermost loop (`k` loop for the temporary matrix `tmp` and matrix `D` multiplication and accumulation), enable parallel reduction:\n  - `#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}` / `#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}`: Apply parallel reduction to the accumulation operation within the loop and automatically determine the optimal parallelism factor.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 32\n__PARA__L4: 2\n__PARA__L5: 1\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: \n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Optimize the given 2mm kernel function for hardware acceleration with dynamic loop configuration directives: Define this function as a target for acceleration, automatically select the optimal pipelining strategy for the loop iterations to enable potential overlap of loop iterations, dynamically tile the loops to enable more efficient use of local memory and parallel execution, and employ parallel processing for loop iterations with automatic factor selection to improve loop execution times, while also specifying reduction on certain variables to maintain correct dependency resolution.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 8\n__PARA__L1: 8\n__PARA__L2: 2\n__PARA__L3: 4\n__PARA__L4: 32\n__PARA__L5: 1\n__PIPE__L0: \n__PIPE__L1: off\n__PIPE__L2: \n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Instruct the compiler to optimize the function 'kernel_2mm' for hardware acceleration and apply automatic loop optimizations for pipelining, tiling, and parallelism where suitable, with specific tags for each directive to allow fine-tuning later. Within the first nested loops, automatically optimize the accumulation into 'tmp' using parallel reduction. In the second nested loops, apply the same technique to update 'D' with the product of 'tmp' and 'C', while scaling 'D' by the scalar 'beta'. Use automatic settings for all #pragma directive parameters, which will be adjusted during design space exploration.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 4\n__PARA__L4: 4\n__PARA__L5: 50\n__PIPE__L0: off\n__PIPE__L1: \n__PIPE__L2: off\n__PIPE__L3: \n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Generate HLS C code for a 2mm kernel function that performs a two-stage matrix multiplication and add operation, marking it for hardware acceleration. Loop pipelining, tiling, and parallel processing should be automatically optimized by the compiler. In the first stage, initialize a temporary matrix by multiplying `alpha` with the product of matrices `A` and `B`, using parallel reduction to accumulate products. In the second stage, multiply matrix `D` by `beta`, and then add the product of the temporary matrix with matrix `C`, again using parallel reduction for accumulation. Use automated pragma values suitable for each loop level and specify automatic factor decisions for pipelining, tiling, and parallelism, while ensuring that accumulations are handled correctly with the reduction clause.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 8\n__PARA__L1: 4\n__PARA__L2: 2\n__PARA__L3: 4\n__PARA__L4: 32\n__PARA__L5: 1\n__PIPE__L0: \n__PIPE__L1: off\n__PIPE__L2: \n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Designate the following function 'kernel_2mm' as a hardware acceleration kernel. Within this kernel, implement matrix multiplication and addition operations where matrix D is updated as D = alpha * A * B * C + beta * D. For the matrix multiplication, firstly initialize a temporary matrix 'tmp' with zeroes. Then, for each pair of outer loop indices 'i' and 'j', calculate the inner products of the 'ith' row of matrix A and the 'jth' column of matrix B, scaled by the factor 'alpha', and store the results in the 'tmp' matrix. Subsequently, update each element of matrix D by multiplying it by 'beta' and adding the product of the corresponding elements from the 'tmp' matrix and matrix C. \n\nOptimize this implementation by allowing the HLS tool to automatically decide whether to pipeline each loop, how to tile each loop for better use of local memory, and how many instances of each loop to run in parallel. Also, apply parallel reduction to the innermost loops where the 'tmp' and 'D' arrays are being updated to ensure efficient accumulation of the partial products. Use the respective automatic optimization pragnas for pipeline, tiling, and parallel factors before each loop nest.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 4\n__PARA__L4: 32\n__PARA__L5: 16\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: \n__PIPE__L3: off\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 8"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Designate the function 'kernel_2mm' as a hardware acceleration kernel. Enable automatic optimization for outer and inner loops through pipelining, tiling, and parallel processing where the specific factors for each should be determined by the compiler. Inside the first pair of nested loops, accumulate the product of 'alpha', 'A[i][k]', and 'B[k][j]' into 'tmp[i][j]' with automated parallel reduction. Similarly, within the second pair of nested loops apply 'beta' to 'D[i][j]' and then add the product of 'tmp[i][k]' and 'C[k][j]', again with automated parallel reduction.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 5\n__PARA__L4: 1\n__PARA__L5: 32\n__PIPE__L0: off\n__PIPE__L1: \n__PIPE__L2: flatten\n__PIPE__L3: off\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 2"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Designate the function 'kernel_2mm' as a target for hardware acceleration and optimize its nested loops for parallel execution, automatic pipelining, and optimal resource tiling, while enabling automatic reduction for the specified arrays within parallel sections.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 8\n__PARA__L1: 20\n__PARA__L2: 2\n__PARA__L3: 4\n__PARA__L4: 32\n__PARA__L5: 1\n__PIPE__L0: \n__PIPE__L1: off\n__PIPE__L2: \n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Create a high-level synthesis (HLS) configuration for a 2mm kernel function with the following attributes: Declare the function as a hardware acceleration kernel; Allow the HLS tool to automatically determine the optimal pipeline, tiling, and parallelism factors for all loops within the function; Use loop transformations to optimize matrix multiplications and additions for the matrices 'tmp', 'A', 'B', 'C', and 'D', with dimensions 40x50, 40x70, 70x50, 50x80, and 40x80 respectively; For the first pair of nested loops, enable parallel reduction on 'tmp' with automatic factor, and for the second pair of nested loops, enable parallel reduction on 'D' with automatic factor.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 8\n__PARA__L4: 1\n__PARA__L5: 32\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: flatten\n__PIPE__L3: off\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 2"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Automatically optimize the acceleration and parallelization of a matrix multiplication and addition kernel with specific matrix dimensions by allowing the tool to choose suitable pipelining, tiling, and parallel factors, and also enable the reduction of intermediate results in the parallel sections of the code.\n\n- Treat `kernel_2mm` function as a hardware acceleration kernel.\n- Enable automatic pipelining for the first and second level loops to improve performance by overlapping iterations.\n- Allow for automatic tiling in the first and second level loops to enhance data reuse and reduce memory bandwidth.\n- Enable automatic parallelization factors in the first and second level loops to run iterations concurrently whenever possible for performance gain.\n- For the innermost loops that accumulate the products (`tmp[i][j] += alpha * A[i][k] * B[k][j];` and `D[i][j] += tmp[i][k] * C[k][j];`), allow automatic parallelization with enabled reductions to efficiently sum up the results across iterations.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 8\n__PARA__L1: 2\n__PARA__L2: 2\n__PARA__L3: 4\n__PARA__L4: 32\n__PARA__L5: 1\n__PIPE__L0: \n__PIPE__L1: off\n__PIPE__L2: \n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Designate the 'kernel_2mm' function as a hardware acceleration kernel, then apply automatic pipelining, tiling, and parallelization optimizations to each loop within the nested loop structures for matrix multiplication and addition. Specifically, for the two outermost loops (labeled L0 and L1), automatically determine the best pipelining, tiling, and parallel factors. For the two middle loops (labeled L2 and L3), again enable automatic optimization decisions for pipelining, tiling, and parallelization. Finally, within the two innermost loops (labeled L4 and L5), set up parallel reduction on the 'tmp' and 'D' arrays respectively, allowing the compiler to automatically choose the most efficient factor for parallel execution.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 8\n__PARA__L1: 1\n__PARA__L2: 2\n__PARA__L3: 4\n__PARA__L4: 32\n__PARA__L5: 1\n__PIPE__L0: \n__PIPE__L1: off\n__PIPE__L2: \n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Generate High-Level Synthesis (HLS) code for a kernel function 'kernel_2mm' that performs a 2-mm (two matrix-matrix multiplications) operation. The function takes the dimensions 'ni', 'nj', 'nk', 'nl', and the matrices 'A', 'B', 'C', 'D', as well as the scalars 'alpha' and 'beta'. You must optimize the loops using the following directives:\n\n1. Mark the function as a hardware kernel using '#pragma ACCEL kernel'.\n2. Automatically determine the best pipelining strategy for the first loop across 'i' with a pragma marked with __PIPE__L0.\n3. Let HLS choose the tiling factor for this loop automatically with __TILE__L0.\n4. For parallel execution, allow HLS to automatically decide the number of iterations that can run in parallel with __PARA__L0.\n5. Pipeline the innermost 'j' loop automatically and tag it with __PIPE__L2.\n6. Automatically set the tiling factor for the 'j' loop with __TILE__L2.\n7. Determine the parallelism factor for 'j' automatically with __PARA__L2.\n8. Enable parallel reduction on the variable 'tmp' within the 'k' loop and let HLS decide the factor with __PARA__L4.\n9. For the second major loop over 'i', enable automatic pipeline optimization with __PIPE__L1.\n10. Use auto tiling for this loop tagged with __TILE__L1.\n11. Automatically decide the parallel factor for this loop with __PARA__L1.\n12. In the inner multiplication loop across 'j', use automatic pipelining with __PIPE__L3.\n13. The tiling factor for this loop should be decided by HLS with __TILE__L3.\n14. Automatically parallelize the loop with HLS-chosen factor __PARA__L3.\n15. For the reduction on the 'D' array, apply parallel reduction and allow HLS to auto-determine the factor with __PARA__L5.\n\nComment on the initialization and multiplication operations accordingly inside the code, and remember to delimit the sections of the operation accessible for HLS optimizations with '#pragma scop' and '#pragma endscop' accordingly.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 4\n__PARA__L3: 80\n__PARA__L4: 1\n__PARA__L5: 1\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: flatten\n__PIPE__L3: \n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Create an HLS C code for a 2mm kernel function that accelerates the matrix multiplication and addition process, with the following characteristics and accompanying pragmas:\n\n1. Declare the function `kernel_2mm` with integer parameters `ni`, `nj`, `nk`, `nl` and double parameters `alpha`, `beta`, and with 2D array parameters `tmp`, `A`, `B`, `C`, and `D` of fixed sizes, as the hardware acceleration kernel.\n\n2. Conduct the multiplication and addition as `D := alpha*A*B + beta*D` in two separate nested loop structures.\n\n3. In the first loop structure, calculate `tmp = alpha*A*B`:\n   - Automatically optimize the outer loop (over `i`) with pipelining.\n   - Use automatic tiling for the outer loop to break it into smaller, more manageable chunks.\n   - Automatically set the parallelism factor for the outer loop for concurrent execution of iterations where possible.\n   - Within the outer loop, for the inner loop (over `j`), also apply automatic pipelining, tiling, and parallelism directives.\n   - For the innermost loop (over `k`), apply automatic parallelism and enable a reduction operation on the `tmp` array to accumulate the results.\n\n4. In the second loop structure, calculate `D = beta*D + tmp*C`:\n   - Apply automatic pipelining, tiling, and parallelism directives to the outer loop over `i`.\n   - For the inner loop (over `j`), similarly apply automatic pipelining, tiling, and parallelism.\n   - Ensure the innermost loop (over `k`) uses parallelism with automatic factor determination and has a reduction operation on the `D` array for accumulating the results.\n\n5. Use a placeholder like `__PIPE__L0`, `__TILE__L0`, `__PARA__L0` for the pragma attribute values to signify that the specific values for pipelining, tiling, and parallelism factors are to be automatically determined by the HLS tool during compilation, with different placeholders for each loop level.\n\nHere is the simplified instruction for all the pragmas used:\n\n- Treat the `kernel_2mm` function as a hardware kernel for acceleration with automatic optimizations.\n- For each of the two loop structures, auto-optimize the outer loop with pipelining, tiling, and parallelism, and apply the same for inner loops along with a reduction pragma with automatic factor for the innermost loops to accumulate the multiplication results in the `tmp` or `D` arrays, respectively. Use placeholders for the tool to automatically determine specific pragma values for each loop nest.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 4\n__PARA__L1: 1\n__PARA__L2: 2\n__PARA__L3: 1\n__PARA__L4: 32\n__PARA__L5: 1\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: \n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Define a hardware acceleration kernel for a 2mm matrix-matrix computation, where the first loop block calculates an intermediate matrix product between matrices A, B, and scalar alpha with automatic optimization for pipelining, tiling, and parallel processing. The second loop block updates matrix D by multiplying it with scalar beta and adding the product of the intermediate matrix with matrix C, also optimized automatically for pipelining, tiling, and parallel processing. Additionally, enable parallel reduction for the summations within each loop block. Use automatic factor determination for all optimizations.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 8\n__PARA__L4: 1\n__PARA__L5: 50\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: \n__PIPE__L3: \n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 2"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Define a function as a hardware kernel for acceleration. Within this function, implement a double matrix multiplication with scaling, where `D` is assigned the result of `alpha*A*B + beta*D`. Optimize the loops through automatic pipelining, tiling, and parallelization, allowing the HLS tool to determine the best values for these optimizations. In nested loops computing the matrix products, apply parallel reduction to intermediate results `tmp` and `D`, with the exact parallelization factors chosen by the HLS tool for optimal performance.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 5\n__PARA__L4: 70\n__PARA__L5: 1\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: off\n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Designate the function `kernel_2mm` to be a hardware acceleration kernel, and for all loops within it, allow the compiler to automatically determine pipeline settings, tiling factors, and parallelization factors. Apply a parallel reduction to the innermost loops where temporary arrays `tmp` and `D` are being updated.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 8\n__PARA__L4: 4\n__PARA__L5: 50\n__PIPE__L0: off\n__PIPE__L1: \n__PIPE__L2: \n__PIPE__L3: \n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Designate the function 'kernel_2mm' as a hardware acceleration kernel, automatically optimize the loop pipelining, tiling, and parallelism for all loops. Specifically, for the loop calculating 'tmp', perform a parallel reduction on 'tmp' with automatic factor adjustment, and for the loop updating 'D', perform a parallel reduction on 'D' with automatic factor adjustment. Use the default or auto values for pipeline, tile, and parallel factors where indicated.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 5\n__PARA__L4: 70\n__PARA__L5: 50\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: off\n__PIPE__L3: off\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Please generate the HLS (High-Level Synthesis) C code for a 2mm kernel function that performs a doubly nested matrix multiplication and accumulation as follows:\n\n1. The function `kernel_2mm` should accept integer dimensions `ni`, `nj`, `nk`, and `nl`, along with double-precision floating-point scalar factors `alpha` and `beta`, and double-precision floating-point 2-dimensional arrays `tmp`, `A`, `B`, `C`, and `D`.\n2. Use `#pragma ACCEL kernel` to indicate the `kernel_2mm` function should be treated as a hardware acceleration kernel.\n3. For the first main loop, which iterates over matrix `tmp`, enable automatic pipelining, tile partitioning, and parallel processing with the respective pragmas set to automatically determine their factors.\n4. Within this main loop, for the inner loop calculating the dot product for `tmp`, apply a parallel pragma with automatic factor and a reduction clause for the `tmp` array.\n5. For the second main loop, which iterates over matrix `D`, use similar pragmas for pipelining, tiling, and parallel processing, allowing automatic decision on factors as before.\n6. Within this main loop, for the inner loop that multiplies the `tmp` matrix by array `C` and accumulates into `D`, apply a parallel pragma with automatic factor and a reduction clause for the `D` matrix.\n\nNote: Make sure to use the loop iterator variables `i`, `j`, and `k` appropriately and initialize `tmp[i][j]` and `D[i][j]` at the correct places in the loops. The first two-dimensional loop iterates `i` from 0 to `ni` (40) and `j` from 0 to `nj` (50), and the k-loop iterates from 0 to `nk` (70). The second two-dimensional loop iterates `i` from 0 to `ni` (40) and `j` from 0 to `nl` (80), and the k-loop iterates from 0 to `nj` (50). The computations should follow the equation `D := alpha * A * B * C + beta * D`, ensuring matrix dimensions align correctly for multiplication.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 4\n__PARA__L4: 1\n__PARA__L5: 50\n__PIPE__L0: off\n__PIPE__L1: \n__PIPE__L2: flatten\n__PIPE__L3: \n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Designate the following function as a hardware acceleration kernel, for the operation D := alpha * A * B * C + beta * D. Automatically determine the best pipelining, tiling, and parallelism strategies for the two nested loop constructs performing matrix operations. In the first double-nested loop, initialize a temporary matrix 'tmp' with zeroes and compute the product of A and B scaled by 'alpha'. In the second double-nested loop, scale matrix 'D' by 'beta' and add the product of the temporary matrix and C. Additionally, apply automatic parallelism with data reduction for the innermost loop calculations involving 'tmp' and 'D'.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 8\n__PARA__L1: 1\n__PARA__L2: 2\n__PARA__L3: 2\n__PARA__L4: 32\n__PARA__L5: 1\n__PIPE__L0: \n__PIPE__L1: off\n__PIPE__L2: \n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Generate an HLS C code for a 2mm kernel function, where the function should be compiled as a hardware acceleration kernel. Automatically optimize the pipeline, tiling, and parallelization for each loop level, allowing the compiler to determine the best factor values. At the outermost loop for matrix multiplication, enable automatic optimization for pipelining, tiling, and parallelism. Inside the first nested loop, which initializes the temporary matrix, allow for the automatic determination of parallel factors along with automatic pipelining and tiling, specifically enabling parallel reduction on the temporary matrix. For the second pair of nested loops, use similar automatic optimizations for updating matrix D with a parallel reduction enabled. Use the following pragmas with the respective loop levels:\n\n1. Treat the overall function as a hardware acceleration kernel.\n2. At the first level of loop nesting (`i` loop for temporary matrix creation), automatically optimize for pipelining (#pragma ACCEL PIPELINE auto), tiling (#pragma ACCEL TILE FACTOR=auto), and parallel execution (#pragma ACCEL PARALLEL FACTOR=auto).\n3. At the second level of loop nesting (`j` loop for temporary matrix creation), replicate the same optimizations as the first level and add a parallel reduction on the temporary matrix.\n4. At the third level of loop nesting (`i` loop for final matrix D update), repeat the same automated optimizations as the first level.\n5. At the fourth level of loop nesting (`j` loop for final matrix D update), again replicate the optimizations and provide for a parallel reduction on matrix D.\n\nEnsure that you use the correct placeholder for the automatic optimization value, denoted as `{__PIPE__L#}`, `{__TILE__L#}`, and `{__PARA__L#}`, where `#` is replaced by the loop level index.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 8\n__PARA__L1: 5\n__PARA__L2: 2\n__PARA__L3: 4\n__PARA__L4: 32\n__PARA__L5: 1\n__PIPE__L0: \n__PIPE__L1: off\n__PIPE__L2: \n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Instruct the HLS tool to treat the `kernel_2mm` function as an acceleration kernel, and apply helpful optimizations such as loop tiling, pipelining, and parallelism automatically for all loops to enhance performance. Specifically, for the outermost loops `i` and `j` in both segments of the 2D matrix multiplication and accumulation, enable automatic pipelining, automatic tiling, and automatic parallelization. For the innermost loops `k`, where temporary arrays `tmp` and `D` are being updated, apply parallel reductions with the factor set to automatic optimization as well. Use the respective automatic optimization pragmas for each optimization directive.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 5\n__PARA__L4: 1\n__PARA__L5: 1\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: flatten\n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "To generate the HLS code provided, instruct the HLS tool as follows using natural language:\n\n\"Define a function named 'kernel_2mm' for hardware acceleration to compute the matrix multiplication and addition: D = alpha * A * B * C + beta * D. The matrices A, B, C, and D have fixed sizes corresponding to the dimensions 40x70, 70x50, 50x80, and 40x80 respectively, and use 'double' data type elements. Also, create a temporary matrix 'tmp' with a size of 40x50. Apply automatic optimization directives to efficiently handle the nested loops for computing matrix operations.\n\nFor the outermost two loops iterating over matrix 'D' indices (with variables 'i','j'), automatically optimize the loops' pipelining, tiling, and parallel processing without specifying the factors. For the nested loops within them (with variable 'k'), direct the tool to automatically optimize parallel processing with a reduction on the 'D' matrix, also without specifying the factor. Follow a similar pattern for the loops operating on the 'tmp' matrix, with the nested loop performing a reduction on 'tmp'.\n\nDo not apply any specific values for the pipelining, tiling, and parallel processing pragmas; instead, indicate that the HLS tool should automatically determine these values by using 'auto' with placeholders for the factors, such as `{__PIPE__L0}`, `{__TILE__L0}`, and `{__PARA__L0}` corresponding to each optimization pragma.\n\nNo specific variables or values are mentioned for these pragmas since 'auto' is specified, which tells the HLS tool to make optimization decisions based on its heuristics or defined constraints.\"", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 5\n__PARA__L4: 70\n__PARA__L5: 1\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: \n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Generate High-Level Synthesis (HLS) code for a 2mm kernel function handling matrix multiplication and addition with the following directives:\n\n1. Mark the function `kernel_2mm` as a hardware acceleration kernel.\n2. Automate the pipelining of loops to potentially improve performance without any specified constraints.\n3. Automatically determine the tiling factor for loops to split them into smaller, more manageable chunks for better parallelism.\n4. Allow the compiler to automatically decide the parallelization factor for loops to execute iterations concurrently where possible.\n5. Apply automatic parallel reduction for the specified variable to aggregate results across parallel loop iterations where the reduction operation occurs.\n\nFor every loop, use `auto{__PIPE__Ln}`, `auto{__TILE__Ln}`, and `auto{__PARA__Ln}` to let the HLS tool optimize pipelining, tiling, and parallelism, respectively, at its discretion. Use `reduction = variable` in the parallel pragma to denote where a reduction should be automatically applied, with `variable` being the mutable data structure to reduce upon.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 4\n__PARA__L3: 80\n__PARA__L4: 1\n__PARA__L5: 32\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: flatten\n__PIPE__L3: \n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Designate a function as a hardware acceleration kernel, apply automatic loop pipelining, tiling, and parallelization with compiler-determined factors for the two main 2-D Matrix Multiply (2MM) operations within the function. For reduction operations on the `tmp` and `D` arrays, enable parallelization with reduction clauses and automatically determined factors.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 8\n__PARA__L4: 4\n__PARA__L5: 50\n__PIPE__L0: off\n__PIPE__L1: \n__PIPE__L2: off\n__PIPE__L3: \n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Compile the following C function as a hardware kernel for acceleration, where the matrix multiplication and addition operations within the 2D loop nests are optimized for high-throughput hardware. Automatically determine the optimal pipelining, tiling, and parallel processing strategies for the for-loops, and allow for reduction optimizations in the innermost loops to handle dependencies when accumulating values in the tmp and D arrays.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 8\n__PARA__L4: 1\n__PARA__L5: 1\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: flatten\n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Generate HLS code for a 2mm kernel function processing matrices, where the function is designated as a hardware acceleration kernel. The external loops for 'i' and 'j' should be automatically optimized using pipelining, tiling, and parallel processing, with specific optimization factors decided by the HLS tool. Internally, nest two pairs of loops: the first pair calculates the matrix multiplication of A and B, scaling by 'alpha' and storing the result in 'tmp'; use automatic parallelization with a pragma indicating a reduction on 'tmp' for the innermost 'k' loop. The second pair of loops scales matrix D by 'beta', then updates it by adding the product of 'tmp' and C, with automatic parallel processing applying reduction on 'D' in the innermost 'k' loop. Set optimization directives for both pairs of loop nests to let the HLS tool auto-optimize pipeline, tile, and parallel factors. Use 'auto' placeholders to indicate the directive values that the HLS tool should automatically decide.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 5\n__PARA__L4: 1\n__PARA__L5: 32\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: flatten\n__PIPE__L3: \n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 2"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Designate the function `kernel_2mm` as a hardware acceleration kernel, apply automatic optimization directives to manage data movement and loop execution, including pipelining, tiling, and parallelism with system-determined parameters. Specifically:\n\n1. Enable the function `kernel_2mm` as a hardware acceleration kernel.\n2. For the outer loop iterating `i` over the range `0` to `39`, initiate:\n   - Automatic pipelining to overlap loop iterations for potential throughput increase.\n   - Automatic tiling to partition the loop into smaller, more manageable blocks if beneficial.\n   - Automatic parallelism to run loop iterations concurrently if possible.\n\n3. Inside this outer loop, for the nested loop iterating `j` over the range `0` to `49`, employ:\n   - Automatic pipelining to similarly improve iteration overlap.\n   - Automatic tiling to possibly split the loop into blocks.\n   - Automatic parallelism to execute iterations simultaneously.\n   - For the innermost loop iterating `k` from `0` to `69`, use automatic parallelism with reduction on `tmp` to accumulate results across iterations, allowing for concurrent updates with proper handling of dependencies.\n\n4. Following the computation of `tmp`, proceed with a loop that iterates `i` over the same range `0` to `39`, and use the same optimization directives with automatic parameters (pipelining, tiling, and parallelism).\n\n5. For the nested loop iterating `j` over the range `0` to `79`, replicate the automatic pipelining, tiling, and parallelism directives.\n   - Within this loop, for the innermost loop iterating `k` from `0` to `49`, establish automatic parallelism with reduction on `D`, enabling concurrent updates with appropriate synchronization to aggregate the product `tmp[i][k] * C[k][j]` into `D[i][j]`.\n\nThese strategies are to efficiently compute the matrix operation `D := alpha*A*B*C + beta*D` by optimizing how the loops are unrolled, pipelined, and executed in parallel on the hardware accelerator, each with system-suggested (auto) settings for the factors involved.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 5\n__PARA__L4: 1\n__PARA__L5: 1\n__PIPE__L0: off\n__PIPE__L1: \n__PIPE__L2: flatten\n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Designate a function to be synthesized into an FPGA-compatible hardware module and apply automatic performance optimization for loop processing with respective pragmas. Specifically, for the function 'kernel_2mm', do the following:\n\n1. Identify it as a hardware acceleration kernel.\n2. For the outermost loops in the two nested loop sections, enable automatic pipelining, tile partitioning, and parallel processing to allow the HLS tool to determine the best factors for each.\n3. Inside the second-level nested loops, automatically apply pipelining, tile partitioning, and parallelism as well.\n4. For the innermost loops that calculate 'tmp' and 'D', set up parallel reduction operations with automatic factor determination for efficient accumulation across iterations.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 8\n__PARA__L4: 1\n__PARA__L5: 50\n__PIPE__L0: off\n__PIPE__L1: \n__PIPE__L2: flatten\n__PIPE__L3: off\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Designate the function 'kernel_2mm' to be optimized for hardware acceleration, applying automatic optimizations for pipelining, data tiling, and parallelism at all levels of the loop nests involved in the 2mm algorithm. Enable parallel reduction for intermediate results within the innermost loops to optimize the matrix multiplication computations. Use compiler directives to automatically determine the best pipeline stages, tile sizes, and parallelism factors for all loops.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 8\n__PARA__L4: 5\n__PARA__L5: 50\n__PIPE__L0: off\n__PIPE__L1: \n__PIPE__L2: \n__PIPE__L3: \n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Translate the provided 2mm kernel function into hardware acceleration with the following optimization directives:\n\n1. For the entire function, target it as a hardware acceleration kernel.\n2. In the first-level `i` loop, automatically determine the optimal loop pipelining, tiling, and parallel processing strategies.\n3. Within the first-level `i` loop, for the second-level `j` loop, also automatically optimize it for pipelining, tiling, and parallel execution.\n4. Enable automatic parallelism for the innermost `k` loop to handle matrix multiplication accumulation in the `tmp` array. Allow the tool to handle any reduction operations needed for `tmp` automatically.\n5. Similarly, in the outer `i` loop for updating matrix `D`, set the loop to automatically be pipelined, tiled, and parallelized.\n6. In the innermost `k` loop for calculating the `D` matrix, enable automatic parallel reduction on the `D` array.\n\nAccordingly, for the directives:\n\n- Use '#pragma ACCEL kernel' before the function definition to indicate the function is an acceleration kernel.\n- Add '#pragma ACCEL PIPELINE auto' before the `i` and `j` loops to enable automatic optimization of loop pipelining for these loops.\n- Place '#pragma ACCEL TILE FACTOR=auto' before the `i` and `j` loops to have the tool automatically select the optimal tiling factor.\n- Use '#pragma ACCEL PARALLEL FACTOR=auto' before the loops to allow the compiler to automatically decide the level of parallel execution for each loop.\n- Apply '#pragma ACCEL PARALLEL reduction' with the corresponding array (`tmp` or `D`) and 'FACTOR=auto' before the `k` loops to enable automated parallel reduction for accumulation.\n\nEnsure to employ the specified '#pragma' values (PIPELINE auto, TILE FACTOR=auto, PARALLEL FACTOR=auto, PARALLEL reduction) at the right points in the code for each respective loop to ensure optimal hardware execution.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 4\n__PARA__L4: 1\n__PARA__L5: 10\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: flatten\n__PIPE__L3: off\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "To generate the HLS codes provided, utilize the following comprehensive but concise instruction:\n\n\"Treat the 'kernel_2mm' function as an accelerated hardware kernel containing two nested loop structures for matrix operations, with automatic optimization directives for pipelining, tiling, and parallelization applied to each loop level to let the HLS tool determine the optimal factors. Additionally, enable automatic parallel reduction for specific variables within the innermost loops.\"\n", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 8\n__PARA__L1: 40\n__PARA__L2: 2\n__PARA__L3: 4\n__PARA__L4: 32\n__PARA__L5: 1\n__PIPE__L0: \n__PIPE__L1: off\n__PIPE__L2: \n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Create an HLS C code for a 2mm kernel function that performs the operation `D := alpha*A*B*C + beta*D` on matrices A, B, C, and D, using loops to iterate over their respective dimensions. Define the kernel function to be a hardware acceleration target. Automatically optimize the loop execution by utilizing pipelining, tiling, and parallelization where the compiler decides the best factor for each optimization strategy. For loop nests that compute matrix multiplication, enable reduction parallelization on the accumulator variables 'tmp' and 'D', and allow the compiler to determine the appropriate parallel factor. Use the following pragma configurations:\n- Mark the entire function as a hardware kernel.\n- Apply automatic pipelining to the outermost loops processing the 'tmp' matrix initialization and the 'D' matrix result update.\n- Set the tile and parallel factors to automatic for both the 'tmp' and 'D' matrix processing loops.\n- Enable automatic pipelining, tiling, and parallelization for the innermost loops that calculate the matrix products and update the 'D' matrix with the results from 'tmp' and 'C', also specifying the accumulation variables 'tmp' and 'D' for reduction parallelism.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 8\n__PARA__L4: 4\n__PARA__L5: 50\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: \n__PIPE__L3: \n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Define a hardware acceleration kernel for a 2mm (two-matrix multiply) computation, which first computes an intermediate matrix `tmp` by multiplying matrix `A` with matrix `B` and then updates matrix `D` by multiplying the intermediate matrix `tmp` with matrix `C` and adding it to matrix `D` scaled by `beta`. Enable automatic optimization for loop pipelining, tiling, and parallelization with HLS pragmas, and use reduction pragmas to specify the accumulation variables (`tmp` and `D`) to enable parallel reduction operations in the innermost loops. The optimization factor levels for pipeline, tile, and parallelization should be set to automatic, allowing the HLS tool to decide the best factors.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 2\n__PARA__L1: 1\n__PARA__L2: 2\n__PARA__L3: 1\n__PARA__L4: 32\n__PARA__L5: 1\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: \n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "For the provided HLS code, use these instructions:\n\n1. Convert the provided function 'kernel_2mm' to a hardware acceleration kernel.\n2. Configure all loops to automatically determine the optimal amount of pipelining, tiling, and parallel processing.\n3. For the two innermost loops calculating 'tmp' and 'D' matrices, enable parallel reduction on the 'tmp' and 'D' arrays respectively, letting the compiler automatically decide the parallel factor.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 8\n__PARA__L4: 1\n__PARA__L5: 50\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: off\n__PIPE__L3: \n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 2"}
{"instruction": "Generate HLS code with the following instructions:", "input": "For each section of your C HLS code, provide the following concise natural language instructions:\n\n1. Designate the 'kernel_2mm' function as a hardware acceleration kernel.\n2. Enable automatic pipelining for the loop handling matrix multiplication and addition of 'tmp', 'A', and 'B', with specific optimization parameters to be determined at compile time.\n3. Enable automatic loop tiling and set the tiling factor for the same loop, with the factor to be determined at compile time, thereby controlling the amount of data processed in each iteration.\n4. Enable parallel processing for the same loop, utilising an automatic factor that allows concurrent execution, as determined at compile time.\n5. For the innermost 'k' loop calculating 'tmp', allow for parallel execution with a reduction on 'tmp', using an automatic parallel factor to control the degree of parallelism.\n\nRepeat steps 2, 3, and 4 for the loop that first scales matrix 'D' by 'beta', and then accumulates the product of 'tmp' and 'C' onto 'D':\n6. Enable automatic loop pipelining, tiling, and parallel processing for this loop sequence, including the inner 'k' loop, applying reduction on 'D' with automatic optimization parameters for each #pragma directive.\n\nFor all #pragma directives requiring optimization parameters (PIPELINE, TILE FACTOR, PARALLEL FACTOR), the 'auto' value indicates that you're delegating the decision for these parameters to the HLS tool, which will decide based on the design constraints and target architecture.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 8\n__PARA__L4: 16\n__PARA__L5: 1\n__PIPE__L0: off\n__PIPE__L1: \n__PIPE__L2: \n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Designate the function `kernel_2mm` to be accelerated as hardware, apply automatic loop pipelining, automatic loop tiling, and automatic parallelization to each nested loop based on the compiler's decision for optimization, and enable automatic parallel reduction for specific inner loops to accumulate results on the `tmp` and `D` arrays. Use compiler directives to specify these settings accordingly for HLS.\n\n- Treat `kernel_2mm` as a hardware kernel for acceleration.\n- For the outermost loop pair (loop variables `i` and `j`) that initializes `tmp`, allow the compiler to automatically:\n  - Pipeline the loop for potential reduction in initiation interval.\n  - Tile the loop to break it into smaller computational blocks if necessary.\n  - Set the parallelism factor to divide loop iterations for concurrent execution.\n- For the innermost loop (loop variable `k`) that calculates values for `tmp`, enable parallel reduction on the `tmp` array.\n- For the second outermost loop pair (loop variables `i` and `j`) that updates `D`, similarly allow the compiler to automatically:\n  - Pipeline the loop.\n  - Tile the loop.\n  - Set the parallelism factor.\n- Lastly, for the innermost loop (loop variable `k`) that calculates values for `D`, enable parallel reduction on the `D` array. Each #pragma should be set to automatically determine its value using the `{auto{__VALUE__}}` syntax where applicable, such as pipeline factor, tile factor, and parallel factor.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 4\n__PARA__L4: 4\n__PARA__L5: 50\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: \n__PIPE__L3: \n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Accelerate the `kernel_2mm` function for matrix multiplication and addition by treating it as a hardware kernel, allowing the compiler to optimize the loops with automatic pipelining, tiling, and parallelization strategies as appropriate while also performing reduction to accumulate the computation results.\n\nSpecifically, instruct the compiler to:\n- Identify and optimize the `kernel_2mm` function as a hardware kernel for acceleration.\n- Automatically determine the best pipelining strategy for the outer loops `i` that iterate over the matrices dimensions 40 and 40 with pragma values `{__PIPE__L0}` and `{__PIPE__L1}` respectively.\n- Automatically select the tiling factors for the `i` and `j` loops, using pragma values `{__TILE__L0}`, `{__TILE__L2}`, `{__TILE__L1}`, and `{__TILE__L3}` respectively.\n- Automatically determine the parallelization factors for the `i`, `j`, and `k` loops, with pragma values `{__PARA__L0}`, `{__PARA__L2}`, `{__PARA__L1}`, `{__PARA__L3}`, `{__PARA__L4}`, and `{__PARA__L5}` respectively.\n- For intermediary results in arrays `tmp` and `D`, apply reduction to combine the values computed across iterations of `k` within the innermost loops, using parallelization with reduction pragmas and automatic factor values `{__PARA__L4}` and `{__PARA__L5}`.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 5\n__PARA__L4: 32\n__PARA__L5: 1\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: \n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 8"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Generate HLS C code for a 2mm matrix multiplication kernel that automatically determines the pipelining, tiling, and parallelization. Implement loop optimizations with automatic factors, enable parallel reductions on temporary matrices, and annotate the function for hardware acceleration. Specifically, these instructions mean:\n\n1. Annotate the `kernel_2mm` function to be treated as a hardware kernel.\n2. In both the top-level loops (processing the dimensions 40x50 and 40x80), automatically choose pipelining, tiling, and parallelization parameters.\n3. Within the nested loops where matrix operations occur:\n   - For the loop updating the `tmp` matrix, automate pipelining, tiling, and parallelization with a focus on parallel reduction on `tmp`.\n   - For the loop updating the `D` matrix, also automate pipelining, tiling, and parallelization with a focus on parallel reduction on `D`.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 8\n__PARA__L1: 1\n__PARA__L2: 2\n__PARA__L3: 1\n__PARA__L4: 32\n__PARA__L5: 1\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: \n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Designate the function 'kernel_2mm' for hardware acceleration, then for each nested loop within the function:\n\n1. Enable automatic optimization of loop pipelining to allow for continuous data streaming within the loop.\n2. Allow the compiler to automatically determine the loop tiling factor, optimizing data processing chunks for spatial locality and performance.\n3. Permit the compiler to automatically set the level of loop parallelization, aiming to execute loop iterations concurrently when possible.\n4. Within the innermost loops where 'tmp' or 'D' is being updated, enable parallel reduction across iterations for these variables to efficiently accumulate their values, letting the compiler decide the optimal parallel factor for these computations.\n\nEach '#pragma ACCEL' directive is followed by 'auto' and a placeholder (e.g., '{__PIPE__L0}'), indicating that the compiler automatically determines appropriate values.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 8\n__PARA__L1: 10\n__PARA__L2: 2\n__PARA__L3: 4\n__PARA__L4: 32\n__PARA__L5: 1\n__PIPE__L0: \n__PIPE__L1: off\n__PIPE__L2: \n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Designate the following function as a hardware acceleration kernel, then optimize matrix multiplication and addition operations using automatic loop pipelining, tiling, and parallelization; apply reductions for intermediate storage in both matrix calculations.\n\nIn the generated code:\n\n1. Treat the function 'kernel_2mm' as the hardware acceleration kernel.\n2. For the first two nested loops with index variables 'i' and 'j', apply automatic loop pipelining, tiling, and parallelization, optimizing for the temporary matrix calculation 'tmp[i][j] += alpha * A[i][k] * B[k][j]' with an additional directive to perform reduction over 'tmp'.\n3. For the second two nested loops with index variables 'i' and 'j', apply automatic loop pipelining, tiling, and parallelization, optimizing for the result matrix update 'D[i][j] += tmp[i][k] * C[k][j]' with an additional directive to perform reduction over 'D' after scaling it by 'beta'.\n4. Allow the tool to automatically determine the values for pipelining, tiling, and parallelization factors by using 'auto' in pragma parameters. The specific values should be represented by placeholders like '__PIPE__L0', '__TILE__L0', and '__PARA__L0', for each respective loop level.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 8\n__PARA__L4: 1\n__PARA__L5: 1\n__PIPE__L0: flatten\n__PIPE__L1: off\n__PIPE__L2: off\n__PIPE__L3: off\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "For the given code that implements a 2-matrix multiplication (2mm) with a subsequent addition, I would describe the necessary HLS pragmas as follows:\n\n1. Mark the `kernel_2mm` function to be treated as a hardware kernel for acceleration with pragma `#pragma ACCEL kernel`.\n\n2. Enable the compiler to automatically determine the optimal pipeline settings for the first loop over 'i' with pragma `#pragma ACCEL PIPELINE auto`.\n\n3. Allow the compiler to automatically choose the best tiling factor for partitioning the first loop over 'i' with pragma `#pragma ACCEL TILE FACTOR=auto`.\n\n4. Permit the compiler to automatically set the degree of parallelism for the first loop over 'i' with pragma `#pragma ACCEL PARALLEL FACTOR=auto`.\n\n5. Similarly, configure the second nested loop over 'j' for automatic pipeline optimization with pragma `#pragma ACCEL PIPELINE auto`.\n\n6. Instruct the compiler to determine the optimal tiling factor automatically for the second nested loop over 'j' with pragma `#pragma ACCEL TILE FACTOR=auto`.\n\n7. Enable automatic parallelism settings for the second nested loop over 'j' with pragma `#pragma ACCEL PARALLEL FACTOR=auto`.\n\n8. For the innermost loop over 'k', while computing 'tmp', apply a reduction to accumulate values efficiently and let the compiler decide the parallel factor automatically with pragma `#pragma ACCEL PARALLEL reduction=tmp FACTOR=auto`.\n\n9. Repeat a similar configuration for the loop nesting level with loop over 'i' and 'j' for updating 'D', using automatic determination of pipeline, tile, and parallel factors with the respective pramas `#pragma ACCEL PIPELINE auto`, `#pragma ACCEL TILE FACTOR=auto`, and `#pragma ACCEL PARALLEL FACTOR=auto`.\n\n10. Finally, for the innermost loop over 'k' when updating 'D', specify a reduction with automatic parallel factor settings using pragma `#pragma ACCEL PARALLEL reduction=D FACTOR=auto`. \n\nEach `auto` directive signals the HLS tool to automatically analyze and optimize the corresponding loop's parallelism, pipelining, or tiling to achieve high performance for the generated hardware.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 8\n__PARA__L4: 5\n__PARA__L5: 50\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: \n__PIPE__L3: \n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Instruct the HLS compiler to treat the provided function as a hardware acceleration kernel, automatically manage the pipelining, tiling, and parallelization of the nested loops with optimization heuristics, and apply parallel reduction for the specified accumulations. Use 'auto' for the compiler to determine the pipelining, tiling, and parallel factors, and mark the intermediate accumulation into 'tmp' and final accumulation into 'D' with reduction.\n\nHere are the instructions in a more structured way:\n\n1. Mark the function `kernel_2mm` as an accelerator kernel.\n2. For the outermost loops `i` (Loop L0 and Loop L1), enable automatic pipelining, tiling, and parallelization without specifying explicit factors.\n3. For the second level loops `j` (Loop L2 and Loop L3), also enable automatic pipelining, tiling, and parallelization.\n4. In Loop L4, apply parallel reduction on the 'tmp' array and set the parallelization factor to automatic.\n5. In Loop L5, apply parallel reduction on the 'D' array and set the parallelization factor to automatic. \n\nFor each automatic pragma, replace the corresponding placeholder with the determined value during synthesis (e.g., `{__PIPE__L0}` with the actual pipelining factor chosen by the compiler).", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 8\n__PARA__L4: 1\n__PARA__L5: 32\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: flatten\n__PIPE__L3: \n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 2"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Accelerate the function `kernel_2mm` using hardware acceleration through High-Level Synthesis (HLS), enable automatic pipeline, tiling, and parallelization optimizations for all loops, and apply parallel reduction for accumulation in selected loops.\n\n- Declare the function `kernel_2mm` with parameters `ni`, `nj`, `nk`, `nl`, `alpha`, `beta`, and double-precision floating-point two-dimensional arrays `tmp`, `A`, `B`, `C`, and `D` as a hardware kernel.\n- In the first set of nested loops, automatically optimize the loop carrying variable `i` to process its iterations with a compiler-determined pipeline, tile factor, and parallel factor.\n- Within the inner loop carrying variable `j`, automatically optimize the loop with a separate pipeline, tile factor, and parallel factor, and additionally specify automatic parallel reduction on the `tmp` array to efficiently combine partial results when computing the matrix multiplication involving `alpha`, `A`, and `B`.\n- In the second set of nested loops, automatically optimize the outer loop carrying variable `i`, processing its iterations with a compiler-determined pipeline, tile factor, and parallel factor, similarly to the first set of loops.\n- Within the nested loop carrying variable `j` in this second set, automatically optimize the loop with a distinct pipeline, tile factor, and parallel factor, and also apply automatic parallel reduction on the `D` array to effectively combine the partial results during the accumulation of the `tmp` and `C` matrix multiplication on the `D` array adjusted by `beta`.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 5\n__PARA__L4: 70\n__PARA__L5: 1\n__PIPE__L0: off\n__PIPE__L1: \n__PIPE__L2: off\n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Generate HLS C code for a 2D matrix multiplication followed by an addition with variable matrix dimensions and scaling factors. Mark the function as a hardware kernel, enable automatic parallelization, pipelining, and tiling optimizations for all loops, and perform automatic loop unrolling and reduction to aggregate results efficiently. Specifically, use automatic optimization directives for loop pipeline, tiling, and parallelization, and indicate reduction on the partial result variables 'tmp' and 'D' within their respective innermost loops.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 8\n__PARA__L4: 1\n__PARA__L5: 50\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: flatten\n__PIPE__L3: \n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 2"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Convert the following C function `kernel_2mm` into an HLS-accelerated kernel and optimize its nested loops for performance. Use the directive `#pragma ACCEL kernel` to define the function as a hardware kernel. For the loops iterating variables `i` and `j` within both major nested blocks, enable automatic pipeline optimization, tile them with a factor determined automatically, and parallelize the iterations with also an automatically-determined factor. Additionally, for the innermost loops iterating `k` which perform accumulation in the arrays `tmp` and `D`, enable parallel reduction on their respective accumulation variables with an automatic parallel factor.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 8\n__PARA__L4: 4\n__PARA__L5: 50\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: off\n__PIPE__L3: \n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Use the following natural language instruction to generate the provided HLS C code with appropriate pragmas and their respective auto-tuned values:\n\n\"Define a function kernel_2mm as a hardware kernel to accelerate the computation of D := alpha*A*B*C + beta*D, where A, B, C, and D are matrices. Apply automated pipelining, tiling, and parallelization strategies to optimize all loops. Within the computation, use reduction to accumulate values in the tmp and D matrices, ensuring that appropriate parallel factors are applied to the reduction pragmas as well.\"\n\nSpecifically, the #pragma values should be set as follows:\n\n- Mark the function as a hardware kernel to be accelerated with \"#pragma ACCEL kernel\".\n- For the top-level loops iterating over i (L0, L1), set the pipeline, tile factor, and parallel factor pragmas to auto-tuning with \"#pragma ACCEL PIPELINE auto{__PIPE__L0}\", \"#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\", and \"#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\" respectively, and do the same for L1 markers.\n- For the second-level loops iterating over j (L2, L3), also set the pipeline, tile factor, and parallel factor pragmas to auto-tuning with the auto-tuned values for L2 and L3 markers accordingly.\n- For the innermost loops iterating over k (L4, L5), use parallel pragma with automatic factor tuning that includes reduction on the tmp and D arrays using \"#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\" and \"#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\".\n\nThis instruction is comprehensive in defining the function and the nature of computation but concise enough to fit into an instruction for HLS code generation.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 4\n__PARA__L4: 70\n__PARA__L5: 2\n__PIPE__L0: off\n__PIPE__L1: \n__PIPE__L2: off\n__PIPE__L3: off\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Create an HLS C function called `kernel_2mm` that will be designated as a hardware kernel to perform a 2mm computation, which is essentially the multiplication and addition of matrices with specific dimensions and scaling factors alpha and beta. The function will first calculate the matrix multiplication of A (40x70) and B (70x50), then scale the result by alpha and store it in a temporary matrix tmp (40x50). Subsequently, the function will scale matrix D (40x80) by beta, perform another matrix multiplication with C (50x80), add the result to the scaled D, and store the final result back into D.\n\nFor each of the nested loops responsible for the matrix computations, leverage automatic loop optimization directives to enhance performance:\n\n1. Allow the compiler to automatically determine the pipeline settings for each loop to enable concurrent execution where iterations can be processed in a pipeline fashion, optimizing throughput (use auto settings since specific values are not provided in the instruction).\n\n2. Permit the compiler to tile the loops, which is the process of breaking down the loop iteration space into smaller chunks that may be executed more efficiently in hardware (use auto settings since specific values are not provided in the instruction).\n\n3. Instruct the compiler to parallelize loop iterations where possible, meaning that multiple iterations can be processed simultaneously, exploiting data parallelism (use auto settings since specific values are not provided in the instruction).\n\n4. For the innermost loop where the multiplication of matrix elements and accumulation into the tmp and D matrices occur, use a parallel reduction with automatic factor determination to facilitate the summation pattern typically required in matrix multiplications. Ensure that this parallel reduction accounts for potential data hazards by aggregating results in a way that avoids write conflicts.\n\nHere are the natural language instructions for each directive:\n- Treat the function `kernel_2mm` as a hardware kernel for acceleration.\n- Automatically determine the loop pipeline settings for each loop to optimize execution overlap and throughput.\n- Allow the compiler to automatically choose loop tiling settings for breaking large loops into efficiently manageable blocks.\n- Enable automatic parallelization of loop iterations to allow concurrent processing of independent iterations.\n- Implement parallel reduction on the innermost loops for the accumulations into the tmp and D matrices with automatic factor determination, ensuring the integrity of the reduction operation.\n\nNOTE: The use of 'auto' within the pragmas indicates that specific values for factors like tiling and parallelization are to be automatically chosen by the HLS tool, rather than being explicitly defined.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 4\n__PARA__L4: 32\n__PARA__L5: 16\n__PIPE__L0: off\n__PIPE__L1: \n__PIPE__L2: \n__PIPE__L3: off\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 8"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Designate the following function as a hardware acceleration kernel, automatically optimize pipeline, tiling, and parallel processing for each loop, with specific optimization factors determined at compile-time, and enable automatic parallel reduction for the innermost loops where 'tmp' and 'D' accumulator variables are updated.\n\n- Treat 'kernel_2mm' as a hardware acceleration kernel.\n- Apply automatic pipeline, tiling, and parallel processing optimization to the outermost loops (loops with indices 'i' and 'j') with factors to be determined during compilation.\n- Use automatic parallel reduction for the innermost accumulations on 'tmp' and 'D' with automatic parallelization factors.\n- Utilize pragma settings that automatically decide optimization values, denoted as 'auto', for pipeline (`__PIPE__Lx`), tiling (`__TILE__Lx`), and parallel processing (`__PARA__Lx`) for each loop level 'Lx'.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 4\n__PARA__L4: 70\n__PARA__L5: 1\n__PIPE__L0: off\n__PIPE__L1: \n__PIPE__L2: off\n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "To generate the provided HLS C code with appropriate pragmas, instruct the code generator with the following comprehensive yet concise directive:\n\n\"Create a hardware kernel function named 'kernel_2mm' designed for matrix multiplication and addition that accelerates the operation `D = alpha * A * B * C + beta * D`. Declare the function with integer parameters ni, nj, nk, nl, double parameters alpha, beta, and double array parameters tmp, A, B, C, D, ensuring that `tmp` has dimensions [40][50], `A` [40][70], `B` [70][50], `C` [50][80], and `D` [40][80]. Inside the function, use nested loops to calculate the temporary matrix multiplication result `tmp = alpha * A * B`, and then update matrix `D` with the operation `D = beta * D + tmp * C`. Apply automatic optimization directives for pipelining, tiling, and parallel execution on all loops with the option to automatically decide the best factors for tiling and parallelism and identify which loops can be pipelined efficiently. Additionally, include a parallel reduction directive for appropriately accumulating values into `tmp` and `D` during the nested loop computations, allowing these accumulations to be done in parallel while considering dependencies among iterations. Ensure that these pragmas are specific about the loops they apply to by using identifiers like __PIPE__L0, __TILE__L0, __PARA__L0, etc., which correspond to different loop levels in the code.\" \n\nTranslate this instruction into HLS C code with corresponding #pragma directives applied to the loops within the `kernel_2mm` function to guide algorithmic optimizations for hardware synthesis.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 5\n__PARA__L4: 1\n__PARA__L5: 50\n__PIPE__L0: off\n__PIPE__L1: \n__PIPE__L2: flatten\n__PIPE__L3: \n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Create an accelerated hardware kernel for a 2-matrix multiplication operation with inner loop reductions, automatically allowing the compiler to determine the optimal pipeline, tile, and parallelism factors for loop execution.\n\nIn this directive-driven HLS code for 2-matrix multiplication:\n\n1. Annotate the function 'kernel_2mm' as a hardware kernel by using `#pragma ACCEL kernel`.\n2. In the first two nested loop constructs, set up automatic optimization for pipeline, tiling, and parallelism strategies with the following:\n   - Enable automatic loop pipelining with `#pragma ACCEL PIPELINE auto`, which will let the compiler decide the best way to pipeline the loops labeled `__PIPE__L0` and `__PIPE__L2`.\n   - Utilize automatic loop tiling with `#pragma ACCEL TILE FACTOR=auto`, permitting the compiler to select the appropriate tile size for the loops labeled `__TILE__L0` and `__TILE__L2`.\n   - Apply automatic parallelism factor with `#pragma ACCEL PARALLEL FACTOR=auto` for potentially concurrent loop iteration execution, using labels `__PARA__L0` and `__PARA__L2`.\n3. For the reduction operation within the third nested loop, enable parallelism with automatic factor determination and specify the variable 'tmp' for reduction using `#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}`.\n4. Repeat a similar setup of automatic pipeline, tile, and parallelism strategies for the next set of nested loops with corresponding nested levels labeled `__PIPE__L1`, `__PIPE__L3`, `__TILE__L1`, `__TILE__L3`, `__PARA__L1`, and `__PARA__L3`.\n5. In the last innermost nested loop, enable parallelism with automatic factor determination and specify 'D' for reduction using `#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}`.\n\nThis HLS code performs the operation `D = alpha * A * B * C + beta * D` in a hardware-accelerated manner, with the compiler optimizing the loop execution strategies automatically based on the annotation hints provided.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 4\n__PARA__L3: 4\n__PARA__L4: 1\n__PARA__L5: 50\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: flatten\n__PIPE__L3: \n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Generate an HLS code for a 2mm kernel function that accelerates the computation of the matrix multiplication and addition of the form D := alpha*A*B + beta*D, where D is ni x nl, A is ni x nk, B is nk x nj, and C is nj x nl matrices, and alpha and beta are scalar values. The function takes as input the dimensions ni, nj, nk, nl, and the matrices A, B, C, D, with D being updated in place. Use automated pragmas to enable loop pipelining, loop tiling, and parallel loop execution, allowing the HLS tool to automatically determine the optimal parameters for these optimizations. Additionally, apply automatic parallel reduction for the accumulation variables tmp and D in the innermost loops, letting the HLS tool decide the parallel factor. Treat the entire function as an accelerated hardware kernel.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 8\n__PARA__L1: 1\n__PARA__L2: 2\n__PARA__L3: 16\n__PARA__L4: 32\n__PARA__L5: 1\n__PIPE__L0: \n__PIPE__L1: off\n__PIPE__L2: \n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Designate the following function as a hardware acceleration kernel, automate the optimization for pipelining, tiling, and parallel processing for the loops with appropriate factors, and apply reduction on temporary variables to accumulate results concurrently in the innermost loops.\n\n- Mark the function 'kernel_2mm' as a hardware acceleration kernel.\n- For each loop nest, enable automatic pipelining, automatic selection of tiling factor, and automatic determination of parallelism factor.\n- In the innermost loops that accumulate into 'tmp' and 'D', enable automatic parallelism with a reduction on the respective array to allow concurrent updates.\n\nSpecifically:\n- Use '#pragma ACCEL kernel' to indicate the function is for hardware acceleration.\n- Apply '#pragma ACCEL PIPELINE auto' with placeholders like '{__PIPE__L0}' to let the tool automatically decide if and how to pipeline the loop.\n- Use '#pragma ACCEL TILE FACTOR=auto' with placeholders like '{__TILE__L0}' for the tool to automatically decide the factor for tiling the loops to optimize memory access.\n- For parallelism, insert '#pragma ACCEL PARALLEL FACTOR=auto' with placeholders like '{__PARA__L0}' to allow the tool to automatically decide the factor of parallel execution.\n- For the 'tmp' and 'D' update loops, enable parallel reduction with '#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto' and '#pragma ACCEL PARALLEL reduction = D FACTOR=auto', respectively, letting the tool find the optimal parallelization scheme for these accumulative operations.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 8\n__PARA__L4: 16\n__PARA__L5: 1\n__PIPE__L0: off\n__PIPE__L1: \n__PIPE__L2: off\n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "To generate the HLS C code that performs a 2mm kernel computation consisting of matrix-matrix multiplications and additions on matrices with specified dimensions, using hardware acceleration pragmas to optimize performance:\n\n1. Designate the entire function as a hardware kernel for acceleration with an auto-detection pragma.\n2. Within the first nested loop structure that performs the interim matrix multiplication and stores the result in 'tmp', apply automatic pragma directives for pipelining, tiling, and parallelism in the outer two loops to allow the HLS tool to determine the best factors for these optimizations.\n3. Include a pragma directive within the innermost loop of this block to enable parallel reduction on 'tmp' array elements, with an automatic factor selection, ensuring parallel computations while performing the additions.\n4. In the second nested loop structure, which scales the 'D' matrix by 'beta' and adds the result of the previous operation, repeat the use of automatic pipelining, tiling, and parallelism pragmas in the outer loops as before.\n5. Similarly, apply a parallel reduction pragma within the innermost loop for updating the 'D' matrix, allowing for concurrent operations while ensuring the integrity of the result.\n\nNote: The exact values of factors are to be determined automatically by the HLS tool, as indicated by the 'auto' keyword along with placeholders for each pragma (e.g., `{__PIPE__L0}`, `{__TILE__L0}`, and `{__PARA__L0}`). These placeholders will be replaced by the HLS tool with appropriate values during the synthesis process.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 4\n__PARA__L4: 70\n__PARA__L5: 1\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: off\n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Designate the function 'kernel_2mm' as a hardware acceleration kernel, and apply the following directives to optimize its loops for performance using High-Level Synthesis:\n\n1. Allow the synthesis tool to automatically determine the best pipelining strategy for the outer loops of both the matrix multiplication and the matrix addition processes (these are the loops iterating over 'i' and 'j' dimensions).\n   \n2. Permit the tool to automatically choose tiling factors for the same outer loops, facilitating parallelism by operating on smaller, more manageable data blocks.\n\n3. Enable automatic determination of parallelization factors for these outer loops, allowing simultaneous calculations where no data dependencies exist.\n\n4. For the innermost loops (these are the loops iterating over 'k' dimension) in both computational sections, invoke parallel reduction on the 'tmp' and 'D' 2D arrays respectively, while also allowing the tool to determine parallelization factors. These pragma directives support concurrent accumulation into the 'tmp' and 'D' arrays while preserving the order of summing elements.\n\nEnsure all the above directives feature automatic decision-making by the synthesis tool for optimal values, signified in the code through placeholders like '__PIPE__LX', '__TILE__LX', and '__PARA__LX' where 'X' denotes the loop level.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 4\n__PARA__L4: 1\n__PARA__L5: 16\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: flatten\n__PIPE__L3: off\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Designate the function 'kernel_2mm' as a hardware acceleration kernel, and enable automated optimization heuristics to manage the parallelism, tiling, and pipelining of the loops for the matrix multiplication and addition operation, ensuring that intermediate and final results accumulate accurately as per the specified reduction variables.\n\n- For the main function, use \"Designate 'kernel_2mm' as a hardware acceleration kernel.\"\n- For the first set of nested loops processing tmp, use:\n  - \"Enable automatic pipeline optimization for the first level loop calculating tmp.\"\n  - \"Automate the selection for tiling factor of the first level loop calculating tmp.\"\n  - \"Automate the selection for parallelism factor of the first level loop calculating tmp.\"\n  - \"Automate the pipeline, tiling, and parallelism optimizations for the second level loop, and use automatic reduction for the 'tmp' matrix.\"\n- For the second set of nested loops processing D, use:\n  - \"Enable automatic pipeline optimization for the first level loop updating D.\"\n  - \"Automate the selection for tiling factor of the first level loop updating D.\"\n  - \"Automate the selection for parallelism factor of the first level loop updating D.\"\n  - \"Automate the pipeline, tiling, and parallelism optimizations for the second level loop, and use automatic reduction for the 'D' matrix.\"", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 5\n__PARA__L4: 1\n__PARA__L5: 50\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: flatten\n__PIPE__L3: \n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Generate HLS C code for a kernel function 'kernel_2mm' that accelerates a 2-matrix multiplication operation with the following characteristics:\n\n1. Treat the entire function as a hardware acceleration kernel.\n2. For the first pair of nested loops (i and j loops) responsible for initializing the 'tmp' matrix and performing the first part of the matrix multiplication (alpha * A * B):\n   - Automatically optimize the pipeline settings for the outer 'i' loop.\n   - Automatically choose the tiling factor for the outer 'i' loop to divide the iteration space into smaller, more manageable chunks.\n   - Automatically set the parallelization factor for the outer 'i' loop to allow iterations to run in parallel where possible.\n   - Within the inner 'j' loop, again automatically optimize the pipeline settings.\n   - Automatically select the tiling factor for the inner 'j' loop.\n   - Automatically set the parallelization factor for the inner 'j' loop.\n   - For the innermost 'k' loop, enable parallelization with reduction on the 'tmp' array and let it automatically determine the parallelization factor.\n\n3. For the second pair of nested loops (i and j loops) responsible for updating the 'D' matrix with the results from the 'tmp' matrix and the final multiplication with matrix 'C':\n   - Automatically optimize the pipeline settings for the outer 'i' loop.\n   - Automatically choose the tiling factor for the outer 'i' loop.\n   - Automatically set the parallelization factor for the outer 'i' loop.\n   - Within the inner 'j' loop, again automatically optimize the pipeline settings.\n   - Automatically select the tiling factor for the inner 'j' loop.\n   - Automatically set the parallelization factor for the inner 'j' loop.\n   - For the innermost 'k' loop, enable parallelization with reduction on the 'D' array and automatically determine the parallelization factor. \n\nThe code involves alpha and beta scaling factors and uses double precision floating-point arithmetic. The matrices A, B, C, and D have dimensions [40][70], [70][50], [50][80], and [40][80], respectively, while the intermediate 'tmp' matrix has dimensions [40][50]. The operation computes D := alpha * A * B * C + beta * D. The code should be enclosed within '#pragma scop' and '#pragma endscop' directives.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 4\n__PARA__L3: 20\n__PARA__L4: 16\n__PARA__L5: 1\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: \n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Designate the given function as a hardware acceleration kernel, while ensuring the compiler automatically determines the optimal settings for pipelining, tiling, and parallel processing of the nested loops, and permits reduction on specific array elements for summations in applicable loops.\n\n- Apply the hardware kernel acceleration directive to the entire `kernel_2mm` function.\n- For the first pair of nested loops which calculate `tmp[i][j]`, allow the compiler to automatically optimize pipeline, tiling, and parallelism settings for the outer and inner loops, and enable automatic parallel reduction on the `tmp` array during the innermost loop.\n- Similarly, for the second pair of nested loops which update `D[i][j]`, instruct the compiler to auto-tune the pipeline, tiling, and parallelism settings for these loops as well, and allow for automatic parallel reduction on the `D` array in the innermost loop.\n\nSpecifically, use \"#pragma ACCEL PIPELINE auto\" for automatically managed pipelining, \"#pragma ACCEL TILE FACTOR=auto\" for compiler-selected tiling factors, \"#pragma ACCEL PARALLEL FACTOR=auto\" for automatic parallel factor determination, and \"#pragma ACCEL PARALLEL reduction=array_name\" for enabling parallel reductions on the mentioned array.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 8\n__PARA__L4: 1\n__PARA__L5: 1\n__PIPE__L0: off\n__PIPE__L1: \n__PIPE__L2: flatten\n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Use the following concise directive to generate the provided HLS code:\n\n\"Define a hardware acceleration function for 2-matrix multiplication and addition, automatically optimizing loops with pipelining, tiling, and parallel processing pragmas, and use automatic factor assignment by the HLS tool. Include reduction pragmas for array accumulations on specific loops.\"\n\nThis instruction encompasses multiple aspects of the provided code:\n\n1. \"**Define a hardware acceleration function for 2-matrix multiplication and addition**\" corresponds to the `#pragma ACCEL kernel` directive, indicating the `kernel_2mm` function is targeted for hardware acceleration.\n\n2. \"**Automatically optimizing loops with pipelining**\" is reflected by the use of `#pragma ACCEL PIPELINE auto{__PIPE__Lx}` directives placed before loops, instructing the HLS tool to automatically determine the best pipelining strategy.\n\n3. \"**Use automatic factor assignment by the HLS tool**\" corresponds to the usage of the `AUTO` keyword and placeholders like `{__PIPE__Lx}`, `{__TILE__Lx}`, and `{__PARA__Lx}` where `x` is the loop level. This indicates that you are letting the HLS tool decide the appropriate pipelining, tiling, and parallelization factors (respectively) rather than specifying them explicitly.\n\n4. \"**Include reduction pragmas for array accumulations on specific loops**\" refers to the `#pragma ACCEL PARALLEL reduction = array` directives within the nested loops, which enable parallel processing and accumulation (`reduction`) into the specified array variable (`tmp` or `D`). The `FACTOR=auto{__PARA__Lx}` allows the HLS tool to automatically optimize the degree of parallelism.\n\nEach `#pragma ACCEL` directive is then applied appropriately to loops or functions in the code, where `PRAGMA_NAME` denotes pipeline, tile, or parallel, and `auto{PLACEHOLDER}` allows for automatic optimization.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 32\n__PARA__L3: 1\n__PARA__L4: 32\n__PARA__L5: 1\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: off\n__PIPE__L3: flatten\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Generate an HLS code in C for a 2mm kernel with the following considerations:\n\n1. Declare the function as a hardware acceleration kernel.\n2. Enable automatic loop pipelining for three nested loops processing a 2D matrix multiplication and addition, where the outermost two loops have dimensions 40x50 and 40x80, and the innermost loops have dimensions 70 and 50 respectively.\n3. Automatically determine the tiling factors for each of these outer loops to split the computation into smaller, more manageable chunks.\n4. Set parallel processing for all loops with automatic factor determination, and specify two parallel reductions for two separate accumulation operations within the respective innermost loops.\n5. Avoid any pragmas that would prevent the automatic optimization features such as pipelining, tiling, or parallelization.\n\nThe specific #pragma values to be used are:\n- `#pragma ACCEL kernel` to indicate that the function is designated for hardware acceleration.\n- `#pragma ACCEL PIPELINE auto` for all loops that you want to be pipelined automatically.\n- `#pragma ACCEL TILE FACTOR=auto` for automatically determining the tiling factor for loops that should be split into sub-loops.\n- `#pragma ACCEL PARALLEL FACTOR=auto` for enabling automatic parallelization on the loops.\n- Use `#pragma ACCEL PARALLEL reduction=<array_name>` to indicate that a reduction operation should be performed on the specified array within the given loop. Use automatic factor determination with `FACTOR=auto`.\n\nEnsure that you're referring to the correct level of the loop hierarchy in your pragmas with appropriate placeholder annotations such as `{__PIPE__L0}`, `{__TILE__L0}`, `{__PARA__L0}`, `{__PIPE__L2}`, and so on, incrementing the level number (e.g., L0, L1, L2...) for each nested loop level.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 1\n__PARA__L3: 5\n__PARA__L4: 70\n__PARA__L5: 50\n__PIPE__L0: off\n__PIPE__L1: \n__PIPE__L2: off\n__PIPE__L3: off\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 1"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Generate an HLS C code for a predefined hardware acceleration kernel responsible for computing a 2mm (two matrix-matrix) operation, optimizing for parallelism and pipelining. This kernel takes sizes of the matrices and the actual matrices along with two scalar factors as inputs. This function performs the calculations \"D := alpha * A * B * C + beta * D\" through a two-step process. \n\nFor the first part of the 2mm computation, employ optimizations as follows:\n\n1. Enable automatic pipelining at the top level of the first part of the computation where the multiply-add operation with matrices A, B, and alpha scalar is conducted, allowing the compiler to determine the best pipeline strategy.\n\n2. Automatically tile the first major loop to allow the compiler to partition the loop iterations into smaller, more manageable chunks, enhancing data locality and parallel processing.\n\n3. Utilize automatic parallelism within the first major loop to enable concurrent execution of independent loop iterations where possible.\n\n4. Within the nested loop that accumulates into 'tmp', apply automatic parallelism and specify a reduction clause to handle writing to the shared 'tmp' array safely, allowing concurrent updates by different parallel iterations.\n\nFor the second part of the 2mm computation:\n\n5. Enable automatic pipelining at the top level of the second part where matrices tmp and C are multiplied and then accumulated into matrix D with a beta scaling factor applied.\n\n6. Automatically tile the first major loop in this second part to further enhance efficiency and exploit fine-grained parallelism.\n\n7. Use automatic parallelism on the loop iterating over 'D' to execute iterations in parallel where dependencies allow.\n\n8. Apply automatic parallelism with reduction in the innermost loop that updates the 'D' array, ensuring safe concurrent accumulations from the 'tmp' and 'C' matrix multiplication.\n\nUse '#pragma ACCEL kernel' to indicate the function should be executed on hardware as a kernel. Additionally, for each loop where optimizations are applied, use the corresponding '#pragma ACCEL PIPELINE auto', '#pragma ACCEL TILE FACTOR=auto', and '#pragma ACCEL PARALLEL FACTOR=auto' directives with placeholder tokens (__PIPE__Lx, __TILE__Lx, __PARA__Lx) which should be replaced with specific values by the optimization tools or the developer as needed. \n\nEnsure to encapsulate the optimized section of the code with '#pragma scop' and '#pragma endscop' to explicitly define the region of interest for analysis and optimization by the HLS toolchain.", "output": "#pragma ACCEL kernel\n\nvoid kernel_2mm(int ni,int nj,int nk,int nl,double alpha,double beta,double tmp[40][50],double A[40][70],double B[70][50],double C[50][80],double D[40][80])\n{\n  int i;\n  int j;\n  int k;\n//#pragma scop\n/* D := alpha*A*B*C + beta*D */\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L0}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L0}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L2}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L2}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}\n    for (j = 0; j < 50; j++) {\n      tmp[i][j] = 0.0;\n      \n#pragma ACCEL PARALLEL reduction = tmp FACTOR=auto{__PARA__L4}\n      for (k = 0; k < 70; ++k) {\n        tmp[i][j] += alpha * A[i][k] * B[k][j];\n      }\n    }\n  }\n  \n#pragma ACCEL PIPELINE auto{__PIPE__L1}\n  \n#pragma ACCEL TILE FACTOR=auto{__TILE__L1}\n  \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}\n  for (i = 0; i < 40; i++) {\n    \n#pragma ACCEL PIPELINE auto{__PIPE__L3}\n    \n#pragma ACCEL TILE FACTOR=auto{__TILE__L3}\n    \n#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L3}\n    for (j = 0; j < 80; j++) {\n      D[i][j] *= beta;\n      \n#pragma ACCEL PARALLEL reduction = D FACTOR=auto{__PARA__L5}\n      for (k = 0; k < 50; ++k) {\n        D[i][j] += tmp[i][k] * C[k][j];\n      }\n    }\n  }\n//#pragma endscop\n}\n------------------\nDesign point:\n------------------\n__PARA__L0: 1\n__PARA__L1: 1\n__PARA__L2: 2\n__PARA__L3: 5\n__PARA__L4: 1\n__PARA__L5: 50\n__PIPE__L0: off\n__PIPE__L1: off\n__PIPE__L2: flatten\n__PIPE__L3: off\n__TILE__L0: 1\n__TILE__L1: 1\n__TILE__L2: 1\n__TILE__L3: 8"}
