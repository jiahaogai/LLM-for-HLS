{"instruction": "Generate HLS code with the following instructions:", "input": "Write a C function named `syr2k` that, using matrix multiplication and addition, computes a symmetric rank-2k operation. The function parameters will include `alpha` and `beta`, which are scalar values, as well as `A`, `B`, `C`, and `D_out`, which are 2D arrays. \n\nThe function will consist of several separate parts: Firstly, it will take the arrays A, B and C, and copy their contents to buffer arrays named `buff_A0`, `buff_A1`, `buff_B0`, `buff_B1` and `buff_C`. It will also create the output array `buff_D_out` and two temporary arrays `tmp1` and `tmp2` and initializes them to 0. \n\nNext, two sets of nested loops will be used to multiply `alpha` by the values in the buffer arrays and sum the results, storing these in the `tmp1` and `tmp2` arrays.\n\nThen, another set of nested loops will add the results from `tmp1`, `tmp2` and `beta` times `buff_C` and store the results to `buff_D_out`.\n\nFinally, there will iterate through `buff_D_out`, and in the case where column `j` is greater than row `i`, it will put a zero in the corresponding position in `D_out`, otherwise it will write the value from `buff_D_out` to `D_out`. Make sure to not break these loops into smaller chunks, run the loop iterations one after the other, not in parallel, and do not automatically pipeline these final loops. Remember to treat the function as a hardware kernel for acceleration.", "output": "#include <stdio.h>\n#include <unistd.h>\n#include <string.h>\n#include <math.h>\n\n#define N 64\n\n#define DATA_TYPE float\n#define SCALAR_VAL(x) x##f\n#define SQRT_FUN(x) sqrtf(x)\n#define EXP_FUN(x) expf(x)\n#define POW_FUN(x,y) powf(x,y)\n\nvoid syr2k(DATA_TYPE alpha, DATA_TYPE beta, DATA_TYPE A[N][N], DATA_TYPE B[N][N], DATA_TYPE C[N][N], DATA_TYPE D_out[N][N]);\n\n\nvoid syr2k(DATA_TYPE alpha, DATA_TYPE beta, DATA_TYPE A[N][N], DATA_TYPE B[N][N], DATA_TYPE C[N][N], DATA_TYPE D_out[N][N]){\n\tint i, j, k;\n\tDATA_TYPE buff_A0[N][N], buff_A1[N][N];\n\tDATA_TYPE buff_B0[N][N], buff_B1[N][N];\n\tDATA_TYPE buff_C[N][N];\n\tDATA_TYPE buff_D_out[N][N];\n\tDATA_TYPE tmp1[N][N];\n\tDATA_TYPE tmp2[N][N];\n\n\n\tlprd_1: for (i = 0; i < N; i++){\n\t\tlprd_2: for (j = 0; j < N; j++){\n\t\t\tbuff_A0[i][j] = A[i][j];\n\t\t\tbuff_A1[i][j] = A[i][j];\n\t\t\tbuff_B0[i][j] = B[i][j];\n\t\t\tbuff_B1[i][j] = B[i][j];\n\t\t\tbuff_C[i][j] = C[i][j];\n\t\t\tbuff_D_out[i][j] = 0;\n\t\t\ttmp1[i][j] = 0;\n\t\t\ttmp2[i][j] = 0;\n\t\t}\n\t}\n\n\tlp1: for (i = 0; i < N; i++){\n\t\tlp2: for (j = 0; j < N; j++){\n\t\t\t// if (j > i) continue;\n\t\t\tlp3: for (k = 0; k < N; k++){\n\t\t\t\ttmp1[i][j] += alpha * buff_A0[i][k] * buff_B0[j][k];\n\t\t\t}\n\t\t}\n\t}\n\n\tlp4: for (i = 0; i < N; i++){\n\t\tlp5: for (j = 0; j < N; j++){\n\t\t\t// if (j > i) continue;\n\t\t\tlp6: for (k = 0; k < N; k++){\n\t\t\t\ttmp2[i][j] += alpha * buff_B0[i][k] * buff_A1[j][k];\n\t\t\t}\n\t\t}\n\t}\n\n\tlp7: for (i = 0; i < N; i++){\n\t\tlp8: for (j = 0; j < N; j++){\n\t\t\t//if (j > i) continue;\n\t\t\tbuff_D_out[i][j] = tmp1[i][j] + tmp2[i][j] + beta * buff_C[i][j];\n\t\t}\n\t}\n\n\tlpwr_1: for(i = 0; i < N; i++){\n\t\tlpwr_2: for(j = 0; j < N; j++){\n\t\t\tif (j > i) D_out[i][j] = 0;\n\t\t\telse D_out[i][j] = buff_D_out[i][j];\n\t\t}\n\t}\n}\n\n"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Create a function 'syrk' in C language that utilizes hardware acceleration and floating-point operations for Symmetric Rank-k operations. The function syrk takes in five parameters: two scalars 'alpha' and 'beta' and three 2D arrays 'A', 'B', and 'C_out', all of type 'DATA_TYPE'. \n\nStart the function by declaring integer variables 'i', 'j', 'k' and buffer arrays buff_A0, buff_A1, buff_B, and buff_C_out the same size as the input arrays. Load data from the input arrays into the buffer arrays in a nested loop tagged as 'lprd_1' and 'lprd_2'.\n\nIn the next series of nested loops tagged 'lp1', 'lp2', and 'lp3', each element of 'buff_C_out' is updated with the product of 'alpha', 'buff_A0' and 'buff_A1'. Follow this up with another pair of nested loops tagged 'lp4' and 'lp5' that update each element of 'buff_C_out' with the product of 'beta' and 'buff_B'.\n\nFinally, using loops 'lpwr_1' and 'lpwr_2', output the 'buff_C_out' values where 'j' is less than or equal to 'i' into 'C_out', and otherwise set 'C_out' to 0. \n\nThis function should treat all major sections and nested loops as individual tasks to be executed in parallel without automatic pipelining and without breaking the loops into smaller chunks for more efficient computation. Use pragma directives such as '#pragma ACCEL TILE FACTOR=1' for no tiling, '#pragma ACCEL PARALLEL FACTOR=1' for no parallel loop iterations, and '#pragma ACCEL PIPELINE \"off\"' to turn off automatic loop pipelining. Use '#pragma ACCEL kernel' at the start of the function to mark it as a hardware kernel.", "output": "#include <stdio.h>\n#include <unistd.h>\n#include <string.h>\n#include <math.h>\n\n#define N 64\n\n#define DATA_TYPE float\n#define SCALAR_VAL(x) x##f\n#define SQRT_FUN(x) sqrtf(x)\n#define EXP_FUN(x) expf(x)\n#define POW_FUN(x,y) powf(x,y)\n\nvoid syrk(DATA_TYPE alpha, DATA_TYPE beta, DATA_TYPE A[N][N], DATA_TYPE B[N][N], DATA_TYPE C_out[N][N]);\n\n\nvoid syrk(DATA_TYPE alpha, DATA_TYPE beta, DATA_TYPE A[N][N], DATA_TYPE B[N][N], DATA_TYPE C_out[N][N]) {\n\tint i, j, k;\n\n\tDATA_TYPE buff_A0[N][N], buff_A1[N][N];\n\tDATA_TYPE buff_B[N][N];\n\tDATA_TYPE buff_C_out[N][N];\n\n\tlprd_1: for (i = 0; i < N; i++) {\n\t\tlprd_2: for (j = 0; j < N; j++) {\n\t\t\tbuff_A0[i][j] = A[i][j];\n\t\t\tbuff_A1[i][j] = A[i][j];\n\t\t\tbuff_B[i][j] = B[i][j];\n\t\t\tbuff_C_out[i][j] = 0;\n\t\t}\n\t}\n\n\tlp1: for (i = 0; i < N; i++) {\n\t\tlp2: for (j = 0; j < N; j++) {\n\t\t\t// if (j > i) continue;\n\t\t\tlp3: for (k = 0; k < N; k++) {\n\t\t\t\tbuff_C_out[i][j] += alpha * buff_A0[i][k] * buff_A1[j][k];\n\t\t\t}\n\t\t}\n\t}\n\n\tlp4: for (i = 0; i < N; i++) {\n\t\tlp5: for (j = 0; j < N; j++) {\n\t\t\t// if (j > i) continue;\n\t\t\tbuff_C_out[i][j] += beta * buff_B[i][j];\n\t\t}\n\t}\n\n\t\n\n\tlpwr_1: for(i = 0; i < N; i++) {\n\t\tlpwr_2: for(j = 0; j < N; j++) {\n\t\t\tif (j > i) C_out[i][j] = 0;\n\t\t\telse C_out[i][j] = buff_C_out[i][j];\n\t\t}\n\t}\n}\n\n"}
{"instruction": "Generate HLS code with the following instructions:", "input": "Write a digit recognition system named 'DigitRec' in HLS C designed for acceleration in FPGA. The system should use a dataset of 18000 training infractions and 2000 test examples, and the digits to be recognized are 4 pixels wide. The data type named 'WholeDigitType' should use 'ap_uint<256>', a 'SDSoC wide vector type'. The physical contiguous memory is used for the acceleration to ensure that global test set, training data set and the results are stored efficiently. This is achieved using '#pragma SDS data mem_attribute'. To optimize the data transfer with the host memory, is utilized the '#pragma SDS data data_mover' to enable AXIDMA_SIMPLE mode. \n\nIn the DigitRec function, use a static training set array and block partition it with the '#pragma HLS array_partition' where the block factor attribute equal to the unrolla_factor, which is 'PAR_FACTOR'. Use the inline function popcount to handle 256 numbers storing into a parallel factor. In the function loop pipeline the run with pragma to achieve better performance.\n\nThe actual recognition is based on a voting system among the nearest neighbors. After preparing the distance measurements, use the 'knn_vote' function with the purpose of collecting the votes for each possible digit (0 to 9) then find the maximum value to determine the label. This function should also be inline for acceleration performance.\n\nFor each training instance, compute the difference to the test instance using XOR operation. Then, find the maximum distance and replace if the computed distance is less than the maximum. For each of the test data, initialize a local array knn_set then fetch a test instance from the test_set inside a loop. This continues as the system keeps updating & computing KNNs.\n\nThe first time the function is called only data transfer is performed then the function returns. For the second call, copy the training and the test set and start processing the test set. The function 'update_knn' is used to keep track of the K minimum distances for a given set. Once the KNN set is updated, compute the final output and store it in the results array. Copy the results back to the globally accessible results array. \n\nAlso, remember to turn off the automatic pipelining optimization for loops related to the data transfer from the memory to the FPGA and operate with the entire loop by using pragma and the ACCEL features such as PIPELINE and PARALLEL.", "output": "/*===============================================================*/\n/*                                                               */\n/*                          digitrec.cpp                         */\n/*                                                               */\n/*             Hardware function for digit recognition           */\n/*                                                               */\n/*===============================================================*/\n\n// dataset information\n#define NUM_TRAINING 18000\n#define CLASS_SIZE 1800\n#define NUM_TEST 2000\n#define DIGIT_WIDTH 4\n\n// typedefs\ntypedef unsigned long long DigitType;\ntypedef unsigned char      LabelType;\n\n// parameters\n#define K_CONST 3\n#define PAR_FACTOR 40\n\n#include \"ap_int.h\"\n// sdsoc wide vector type\ntypedef ap_uint<256>  WholeDigitType;\n\n#pragma SDS data mem_attribute(global_training_set:PHYSICAL_CONTIGUOUS, global_test_set:PHYSICAL_CONTIGUOUS, global_results:PHYSICAL_CONTIGUOUS)\n#pragma SDS data data_mover(global_training_set:AXIDMA_SIMPLE, global_test_set:AXIDMA_SIMPLE, global_results:AXIDMA_SIMPLE)\nvoid DigitRec(WholeDigitType global_training_set[NUM_TRAINING / 2], WholeDigitType global_test_set[NUM_TEST], LabelType global_results[NUM_TEST], int run);\n\n\n// popcount function\nint popcount(WholeDigitType x)\n{\n  // most straightforward implementation\n  // actually not bad on FPGA\n  int cnt = 0;\n  for (int i = 0; i < 256; i ++ )\n    cnt = cnt + x[i];\n\n  return cnt;\n}\n\n// Given the test instance and a (new) training instance, this\n// function maintains/updates an array of K minimum\n// distances per training set.\nvoid update_knn( WholeDigitType test_inst, WholeDigitType train_inst, int min_distances[K_CONST] ) \n{\n  #pragma HLS inline\n\n  // Compute the difference using XOR\n  WholeDigitType diff = test_inst ^ train_inst;\n\n  int dist = 0;\n\n  dist = popcount(diff);\n\n  int max_dist = 0;\n  int max_dist_id = K_CONST+1;\n  int k = 0;\n\n  // Find the max distance\n  FIND_MAX_DIST: for ( int k = 0; k < K_CONST; ++k ) \n  {\n    if ( min_distances[k] > max_dist ) \n    {\n      max_dist = min_distances[k];\n      max_dist_id = k;\n    }\n  }\n\n  // Replace the entry with the max distance\n  if ( dist < max_dist )\n    min_distances[max_dist_id] = dist;\n\n  return;\n}\n\n// Given 10xK minimum distance values, this function\n// finds the actual K nearest neighbors and determines the\n// final output based on the most common int represented by\n// these nearest neighbors (i.e., a vote among KNNs).\nLabelType knn_vote( int knn_set[PAR_FACTOR * K_CONST] ) \n{\n  #pragma HLS inline\n\n  // local buffers\n\n  // final K nearest neighbors\n  int min_distance_list[K_CONST];\n  #pragma HLS array_partition variable=min_distance_list complete dim=0\n  // labels for the K nearest neighbors\n  int label_list[K_CONST];\n  #pragma HLS array_partition variable=label_list complete dim=0\n  // voting boxes\n  int vote_list[10];\n  #pragma HLS array_partition variable=vote_list complete dim=0\n\n  int pos = 1000;\n\n  // initialize\n  INIT_1: for (int i = 0;i < K_CONST; i ++ )\n  {\n    #pragma HLS unroll\n    min_distance_list[i] = 256;\n    label_list[i] = 9;\n  }\n\n  INIT_2: for (int i = 0;i < 10; i ++ )\n  {\n    #pragma HLS unroll\n    vote_list[i] = 0;\n  }\n\n  // go through all the lanes\n  // do an insertion sort to keep a sorted neighbor list\n  LANES: for (int i = 0; i < PAR_FACTOR; i ++ )\n  {\n    INSERTION_SORT_OUTER: for (int j = 0; j < K_CONST; j ++ )\n    {\n      #pragma HLS pipeline\n      pos = 1000;\n      INSERTION_SORT_INNER: for (int r = 0; r < K_CONST; r ++ )\n      {\n        #pragma HLS unroll\n        pos = ((knn_set[i*K_CONST+j] < min_distance_list[r]) && (pos > K_CONST)) ? r : pos;\n      }\n\n      INSERT: for (int r = K_CONST ;r > 0; r -- )\n      {\n        #pragma HLS unroll\n        if(r-1 > pos)\n        {\n          min_distance_list[r-1] = min_distance_list[r-2];\n          label_list[r-1] = label_list[r-2];\n        }\n        else if (r-1 == pos)\n        {\n          min_distance_list[r-1] = knn_set[i*K_CONST+j];\n          label_list[r-1] = i / (PAR_FACTOR / 10);\n        }\n      }\n    }\n  }\n\n  // vote\n  INCREMENT: for (int i = 0;i < K_CONST; i ++ )\n  {\n    #pragma HLS pipeline\n    vote_list[label_list[i]] += 1;\n  }\n\n  LabelType max_vote;\n  max_vote = 0;\n\n  // find the maximum value\n  VOTE: for (int i = 0;i < 10; i ++ )\n  {\n    #pragma HLS unroll\n    if(vote_list[i] >= vote_list[max_vote])\n    {\n      max_vote = i;\n    }\n  }\n\n  return max_vote;\n\n}\n\n// top-level hardware function\n// since AXIDMA_SIMPLE interface does not support arrays with size more than 16384 on interface\n// we call this function twice to transfer data\nvoid DigitRec(WholeDigitType global_training_set[NUM_TRAINING / 2], WholeDigitType global_test_set[NUM_TEST], LabelType global_results[NUM_TEST], int run) \n{\n\n  // This array stores K minimum distances per training set\n  int knn_set[PAR_FACTOR * K_CONST];\n  //#pragma HLS array_partition variable=knn_set complete dim=0\n\n  static WholeDigitType training_set [NUM_TRAINING];\n  // to be used in a pragma\n  const int unroll_factor = PAR_FACTOR;\n  //#pragma HLS array_partition variable=training_set block factor=unroll_factor dim=0\n\n  static WholeDigitType test_set     [NUM_TEST];\n  static LabelType results           [NUM_TEST];\n\n  // the first time, just do data transfer and return\n  if (run == 0)\n  {\n    // copy the training set for the first time\n    lp1:for (int i = 0; i < NUM_TRAINING / 2; i ++ )\n      //#pragma HLS pipeline\n      training_set[i] = global_training_set[i];\n    return;\n  }\n\n  // for the second time\n  lp2:for (int i = 0; i < NUM_TRAINING / 2; i ++ )\n    //#pragma HLS pipeline\n    training_set[i + NUM_TRAINING / 2] = global_training_set[i];\n  // copy the test set\n  lp3:for (int i = 0; i < NUM_TEST; i ++ )\n    //#pragma HLS pipeline\n    test_set[i] = global_test_set[i];\n\n  // loop through test set\n  TEST_LOOP: for (int t = 0; t < NUM_TEST; ++t) \n  {\n    // fetch one instance\n    WholeDigitType test_instance = test_set[t];\n\n    // Initialize the knn set\n    SET_KNN_SET: for ( int i = 0; i < K_CONST * PAR_FACTOR ; ++i ) \n    {\n      #pragma HLS unroll\n      // Note that the max distance is 256\n      knn_set[i] = 256;\n    }\n\n    TRAINING_LOOP : for ( int i = 0; i < NUM_TRAINING / PAR_FACTOR; ++i ) \n    {\n      //#pragma HLS pipeline\n      LANES : for ( int j = 0; j < PAR_FACTOR; j++ ) \n      {\n        //#pragma HLS unroll\n        // Read a new instance from the training set\n        WholeDigitType training_instance = training_set[j * NUM_TRAINING / PAR_FACTOR + i];\n\n        // Update the KNN set\n        update_knn( test_instance, training_instance, &knn_set[j * K_CONST] );\n      }\n    }\n    // Compute the final output\n    LabelType max_vote = knn_vote(knn_set);\n    results[t] = max_vote;\n\n  }\n\n  // copy the results out\n  lp4: for (int i = 0; i < NUM_TEST; i ++ )\n    //#pragma HLS pipeline\n    global_results[i] = results[i];\n\n}\n\n"}
